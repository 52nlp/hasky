{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x80a0810>> ignored\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions 12 and 6 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2542b444d431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# True logits: [batch_size, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#ue_logits = tf.reduce_sum(tf.mul(example_emb, true_w), 1) + true_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mtrue_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;31m# Sampled logits: [batch_size, num_sampled]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# We replicate sampled noise lables for all examples in the batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                                    \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m                                    \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m                                    name=name)\n\u001b[0m\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[0msparse_matmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_mat_mul\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m    912\u001b[0m   \"\"\"\n\u001b[0;32m    913\u001b[0m   return _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[1;32m--> 914\u001b[1;33m                               transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    691\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    692\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m                            op_def=op_def)\n\u001b[0m\u001b[0;32m    694\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2177\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2179\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2180\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2181\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1631\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[0;32m   1632\u001b[0m                          % op.type)\n\u001b[1;32m-> 1633\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1634\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/ops/common_shapes.pyc\u001b[0m in \u001b[0;36mmatmul_shape\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m     92\u001b[0m   \u001b[0minner_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ma_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m   \u001b[0minner_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose_b\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mb_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m   \u001b[0minner_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\"\n\u001b[1;32m---> 98\u001b[1;33m                        % (self, other))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmerge_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions 12 and 6 are not compatible"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "emb_dim = 12\n",
    "init_width = 0.5 / emb_dim\n",
    "vocab_size = 1000\n",
    "batch_size = 6\n",
    "emb = tf.Variable(\n",
    "        tf.random_uniform(\n",
    "            [vocab_size, emb_dim], -init_width, init_width),\n",
    "        name=\"emb\")\n",
    "\n",
    "sm_w_t = tf.Variable(\n",
    "        tf.zeros([vocab_size, emb_dim]),\n",
    "        name=\"sm_w_t\")\n",
    "sm_b = tf.Variable(tf.zeros([vocab_size]), name=\"sm_b\")\n",
    "\n",
    "examples = tf.constant([2,1, 3, 4, 0, 5])\n",
    "labels = tf.constant([1, 0, 4, 3, 5, 2])\n",
    "\n",
    "labels_matrix = tf.reshape(\n",
    "        tf.cast(labels,\n",
    "                dtype=tf.int64),\n",
    "        [batch_size, 1])\n",
    "\n",
    "num_samples = 2\n",
    "sampled_ids, _, _ = (tf.nn.uniform_candidate_sampler(\n",
    "        true_classes=labels_matrix,\n",
    "        num_true=1,\n",
    "        num_sampled=num_samples,\n",
    "        unique=True,\n",
    "        range_max=vocab_size,))\n",
    "\n",
    "# Embeddings for examples: [batch_size, emb_dim]\n",
    "example_emb = tf.nn.embedding_lookup(emb, examples)\n",
    "\n",
    "# Weights for labels: [batch_size, emb_dim]\n",
    "true_w = tf.nn.embedding_lookup(sm_w_t, labels)\n",
    "# Biases for labels: [batch_size, 1]\n",
    "true_b = tf.nn.embedding_lookup(sm_b, labels)\n",
    "\n",
    "# Weights for sampled ids: [num_sampled, emb_dim]\n",
    "sampled_w = tf.nn.embedding_lookup(sm_w_t, sampled_ids)\n",
    "# Biases for sampled ids: [num_sampled, 1]\n",
    "sampled_b = tf.nn.embedding_lookup(sm_b, sampled_ids)\n",
    "\n",
    "# True logits: [batch_size, 1]\n",
    "its = tf.reduce_sum(tf.mul(example_emb, true_w), 1) + true_b\n",
    "true_logits = tf.matmul(example_emb, true_w)\n",
    "# Sampled logits: [batch_size, num_sampled]\n",
    "# We replicate sampled noise lables for all examples in the batch\n",
    "# using the matmul.\n",
    "sampled_b_vec = tf.reshape(sampled_b, [num_samples])\n",
    "sampled_logits = tf.matmul(example_emb,\n",
    "                               sampled_w,\n",
    "                               transpose_b=True) + sampled_b_vec\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_sum in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_sum(input_tensor, reduction_indices=None, keep_dims=False, name=None)\n",
      "    Computes the sum of elements across dimensions of a tensor.\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `reduction_indices`.\n",
      "    Unless `keep_dims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    entry in `reduction_indices`. If `keep_dims` is true, the reduced dimensions\n",
      "    are retained with length 1.\n",
      "    \n",
      "    If `reduction_indices` has no entries, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # 'x' is [[1, 1, 1]\n",
      "    #         [1, 1, 1]]\n",
      "    tf.reduce_sum(x) ==> 6\n",
      "    tf.reduce_sum(x, 0) ==> [2, 2, 2]\n",
      "    tf.reduce_sum(x, 1) ==> [3, 3]\n",
      "    tf.reduce_sum(x, 1, keep_dims=True) ==> [[3], [3]]\n",
      "    tf.reduce_sum(x, [0, 1]) ==> 6\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      reduction_indices: The dimensions to reduce. If `None` (the default),\n",
      "        reduces all dimensions.\n",
      "      keep_dims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reduce_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(self, examples, labels):\n",
    "    \"\"\"Build the graph for the forward pass.\"\"\"\n",
    "    opts = self._options\n",
    "\n",
    "    # Declare all variables we need.\n",
    "    # Embedding: [vocab_size, emb_dim]\n",
    "    init_width = 0.5 / opts.emb_dim\n",
    "    emb = tf.Variable(\n",
    "        tf.random_uniform(\n",
    "            [opts.vocab_size, opts.emb_dim], -init_width, init_width),\n",
    "        name=\"emb\")\n",
    "    self._emb = emb\n",
    "\n",
    "    # Softmax weight: [vocab_size, emb_dim]. Transposed.\n",
    "    sm_w_t = tf.Variable(\n",
    "        tf.zeros([opts.vocab_size, opts.emb_dim]),\n",
    "        name=\"sm_w_t\")\n",
    "\n",
    "    # Softmax bias: [emb_dim].\n",
    "    sm_b = tf.Variable(tf.zeros([opts.vocab_size]), name=\"sm_b\")\n",
    "\n",
    "    # Global step: scalar, i.e., shape [].\n",
    "    self.global_step = tf.Variable(0, name=\"global_step\")\n",
    "\n",
    "    # Nodes to compute the nce loss w/ candidate sampling.\n",
    "    labels_matrix = tf.reshape(\n",
    "        tf.cast(labels,\n",
    "                dtype=tf.int64),\n",
    "        [opts.batch_size, 1])\n",
    "\n",
    "    # Negative sampling.\n",
    "    sampled_ids, _, _ = (tf.nn.fixed_unigram_candidate_sampler(\n",
    "        true_classes=labels_matrix,\n",
    "        num_true=1,\n",
    "        num_sampled=opts.num_samples,\n",
    "        unique=True,\n",
    "        range_max=opts.vocab_size,\n",
    "        distortion=0.75,\n",
    "        unigrams=opts.vocab_counts.tolist()))\n",
    "\n",
    "    # Embeddings for examples: [batch_size, emb_dim]\n",
    "    example_emb = tf.nn.embedding_lookup(emb, examples)\n",
    "\n",
    "    # Weights for labels: [batch_size, emb_dim]\n",
    "    true_w = tf.nn.embedding_lookup(sm_w_t, labels)\n",
    "    # Biases for labels: [batch_size, 1]\n",
    "    true_b = tf.nn.embedding_lookup(sm_b, labels)\n",
    "\n",
    "    # Weights for sampled ids: [num_sampled, emb_dim]\n",
    "    sampled_w = tf.nn.embedding_lookup(sm_w_t, sampled_ids)\n",
    "    # Biases for sampled ids: [num_sampled, 1]\n",
    "    sampled_b = tf.nn.embedding_lookup(sm_b, sampled_ids)\n",
    "\n",
    "    # True logits: [batch_size, 1]\n",
    "    true_logits = tf.reduce_sum(tf.mul(example_emb, true_w), 1) + true_b\n",
    "\n",
    "    # Sampled logits: [batch_size, num_sampled]\n",
    "    # We replicate sampled noise lables for all examples in the batch\n",
    "    # using the matmul.\n",
    "    sampled_b_vec = tf.reshape(sampled_b, [opts.num_samples])\n",
    "    sampled_logits = tf.matmul(example_emb,\n",
    "                               sampled_w,\n",
    "                               transpose_b=True) + sampled_b_vec\n",
    "    return true_logits, sampled_logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
