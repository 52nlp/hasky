{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function string_input_producer in module tensorflow.python.training.input:\n",
      "\n",
      "string_input_producer(string_tensor, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None)\n",
      "    Output strings (e.g. filenames) to a queue for an input pipeline.\n",
      "    \n",
      "    Args:\n",
      "      string_tensor: A 1-D string tensor with the strings to produce.\n",
      "      num_epochs: An integer (optional). If specified, `string_input_producer`\n",
      "        produces each string from `string_tensor` `num_epochs` times before\n",
      "        generating an `OutOfRange` error. If not specified,\n",
      "        `string_input_producer` can cycle through the strings in `string_tensor`\n",
      "        an unlimited number of times.\n",
      "      shuffle: Boolean. If true, the strings are randomly shuffled within each\n",
      "        epoch.\n",
      "      seed: An integer (optional). Seed used if shuffle == True.\n",
      "      capacity: An integer. Sets the queue capacity.\n",
      "      shared_name: (optional). If set, this queue will be shared under the given\n",
      "        name across multiple sessions.\n",
      "      name: A name for the operations (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A queue with the output strings.  A `QueueRunner` for the Queue\n",
      "      is added to the current `Graph`'s `QUEUE_RUNNER` collection.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If the string_tensor is a null Python list.  At runtime,\n",
      "      will fail with an assertion if string_tensor becomes a null tensor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help( tf.train.string_input_producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function embedding_lookup_sparse in module tensorflow.python.ops.embedding_ops:\n",
      "\n",
      "embedding_lookup_sparse(params, sp_ids, sp_weights, partition_strategy='mod', name=None, combiner='mean')\n",
      "    Computes embeddings for the given ids and weights.\n",
      "    \n",
      "    This op assumes that there is at least one id for each row in the dense tensor\n",
      "    represented by sp_ids (i.e. there are no rows with empty features), and that\n",
      "    all the indices of sp_ids are in canonical row-major order.\n",
      "    \n",
      "    It also assumes that all id values lie in the range [0, p0), where p0\n",
      "    is the sum of the size of params along dimension 0.\n",
      "    \n",
      "    Args:\n",
      "      params: A single tensor representing the complete embedding tensor,\n",
      "        or a list of P tensors all of same shape except for the first dimension,\n",
      "        representing sharded embedding tensors.\n",
      "      sp_ids: N x M SparseTensor of int64 ids (typically from FeatureValueToId),\n",
      "        where N is typically batch size and M is arbitrary.\n",
      "      sp_weights: either a SparseTensor of float / double weights, or None to\n",
      "        indicate all weights should be taken to be 1. If specified, sp_weights\n",
      "        must have exactly the same shape and indices as sp_ids.\n",
      "      partition_strategy: A string specifying the partitioning strategy, relevant\n",
      "        if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default\n",
      "        is `\"mod\"`. See `tf.nn.embedding_lookup` for more details.\n",
      "      name: Optional name for the op.\n",
      "      combiner: A string specifying the reduction op. Currently \"mean\", \"sqrtn\"\n",
      "        and \"sum\" are supported.\n",
      "        \"sum\" computes the weighted sum of the embedding results for each row.\n",
      "        \"mean\" is the weighted sum divided by the total weight.\n",
      "        \"sqrtn\" is the weighted sum divided by the square root of the sum of the\n",
      "        squares of the weights.\n",
      "    \n",
      "    Returns:\n",
      "      A dense tensor representing the combined embeddings for the\n",
      "      sparse ids. For each row in the dense tensor represented by sp_ids, the op\n",
      "      looks up the embeddings for all ids in that row, multiplies them by the\n",
      "      corresponding weight, and combines these embeddings as specified.\n",
      "    \n",
      "      In other words, if\n",
      "        shape(combined params) = [p0, p1, ..., pm]\n",
      "      and\n",
      "        shape(sp_ids) = shape(sp_weights) = [d0, d1, ..., dn]\n",
      "      then\n",
      "        shape(output) = [d0, d1, ..., dn-1, p1, ..., pm].\n",
      "    \n",
      "      For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are\n",
      "    \n",
      "        [0, 0]: id 1, weight 2.0\n",
      "        [0, 1]: id 3, weight 0.5\n",
      "        [1, 0]: id 0, weight 1.0\n",
      "        [2, 3]: id 1, weight 3.0\n",
      "    \n",
      "      with combiner=\"mean\", then the output will be a 3x20 matrix where\n",
      "        output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)\n",
      "        output[1, :] = params[0, :] * 1.0\n",
      "        output[2, :] = params[1, :] * 3.0\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If sp_ids is not a SparseTensor, or if sp_weights is neither\n",
      "        None nor SparseTensor.\n",
      "      ValueError: If combiner is not one of {\"mean\", \"sqrtn\", \"sum\"}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.embedding_lookup_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function parse_example in module tensorflow.python.ops.parsing_ops:\n",
      "\n",
      "parse_example(serialized, features, name=None, example_names=None)\n",
      "    Parses `Example` protos into a `dict` of tensors.\n",
      "    \n",
      "    Parses a number of serialized [`Example`]\n",
      "    (https://www.tensorflow.org/code/tensorflow/core/example/example.proto)\n",
      "    protos given in `serialized`.\n",
      "    \n",
      "    `example_names` may contain descriptive names for the corresponding serialized\n",
      "    protos. These may be useful for debugging purposes, but they have no effect on\n",
      "    the output. If not `None`, `example_names` must be the same length as `serialized`.\n",
      "    \n",
      "    This op parses serialized examples into a dictionary mapping keys to `Tensor`\n",
      "    and `SparseTensor` objects. `features` is a dict from keys to `VarLenFeature`\n",
      "    and `FixedLenFeature` objects. Each `VarLenFeature` is mapped to a\n",
      "    `SparseTensor`, and each `FixedLenFeature` is mapped to a `Tensor`.\n",
      "    \n",
      "    Each `VarLenFeature` maps to a `SparseTensor` of the specified type\n",
      "    representing a ragged matrix. Its indices are `[batch, index]` where `batch`\n",
      "    is the batch entry the value is from in `serialized`, and `index` is the\n",
      "    value's index in the list of values associated with that feature and example.\n",
      "    \n",
      "    Each `FixedLenFeature` `df` maps to a `Tensor` of the specified type (or\n",
      "    `tf.float32` if not specified) and shape `(serialized.size(),) + df.shape`.\n",
      "    \n",
      "    `FixedLenFeature` entries with a `default_value` are optional. With no default\n",
      "    value, we will fail if that `Feature` is missing from any example in\n",
      "    `serialized`.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    For example, if one expects a `tf.float32` sparse feature `ft` and three\n",
      "    serialized `Example`s are provided:\n",
      "    \n",
      "    ```\n",
      "    serialized = [\n",
      "      features\n",
      "        { feature { key: \"ft\" value { float_list { value: [1.0, 2.0] } } } },\n",
      "      features\n",
      "        { feature []},\n",
      "      features\n",
      "        { feature { key: \"ft\" value { float_list { value: [3.0] } } }\n",
      "    ]\n",
      "    ```\n",
      "    \n",
      "    then the output will look like:\n",
      "    \n",
      "    ```\n",
      "    {\"ft\": SparseTensor(indices=[[0, 0], [0, 1], [2, 0]],\n",
      "                        values=[1.0, 2.0, 3.0],\n",
      "                        shape=(3, 2)) }\n",
      "    ```\n",
      "    \n",
      "    Given two `Example` input protos in `serialized`:\n",
      "    \n",
      "    ```\n",
      "    [\n",
      "      features {\n",
      "        feature { key: \"kw\" value { bytes_list { value: [ \"knit\", \"big\" ] } } }\n",
      "        feature { key: \"gps\" value { float_list { value: [] } } }\n",
      "      },\n",
      "      features {\n",
      "        feature { key: \"kw\" value { bytes_list { value: [ \"emmy\" ] } } }\n",
      "        feature { key: \"dank\" value { int64_list { value: [ 42 ] } } }\n",
      "        feature { key: \"gps\" value { } }\n",
      "      }\n",
      "    ]\n",
      "    ```\n",
      "    \n",
      "    And arguments\n",
      "    \n",
      "    ```\n",
      "    example_names: [\"input0\", \"input1\"],\n",
      "    features: {\n",
      "        \"kw\": VarLenFeature(tf.string),\n",
      "        \"dank\": VarLenFeature(tf.int64),\n",
      "        \"gps\": VarLenFeature(tf.float),\n",
      "    }\n",
      "    ```\n",
      "    \n",
      "    Then the output is a dictionary:\n",
      "    \n",
      "    ```python\n",
      "    {\n",
      "      \"kw\": SparseTensor(\n",
      "          indices=[[0, 0], [0, 1], [1, 0]],\n",
      "          values=[\"knit\", \"big\", \"emmy\"]\n",
      "          shape=[2, 2]),\n",
      "      \"dank\": SparseTensor(\n",
      "          indices=[[1, 0]],\n",
      "          values=[42],\n",
      "          shape=[2, 1]),\n",
      "      \"gps\": SparseTensor(\n",
      "          indices=[],\n",
      "          values=[],\n",
      "          shape=[2, 0]),\n",
      "    }\n",
      "    ```\n",
      "    \n",
      "    For dense results in two serialized `Example`s:\n",
      "    \n",
      "    ```\n",
      "    [\n",
      "      features {\n",
      "        feature { key: \"age\" value { int64_list { value: [ 0 ] } } }\n",
      "        feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "       },\n",
      "       features {\n",
      "        feature { key: \"age\" value { int64_list { value: [] } } }\n",
      "        feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "      }\n",
      "    ]\n",
      "    ```\n",
      "    \n",
      "    We can use arguments:\n",
      "    \n",
      "    ```\n",
      "    example_names: [\"input0\", \"input1\"],\n",
      "    features: {\n",
      "        \"age\": FixedLenFeature([], dtype=tf.int64, default_value=-1),\n",
      "        \"gender\": FixedLenFeature([], dtype=tf.string),\n",
      "    }\n",
      "    ```\n",
      "    \n",
      "    And the expected output is:\n",
      "    \n",
      "    ```python\n",
      "    {\n",
      "      \"age\": [[0], [-1]],\n",
      "      \"gender\": [[\"f\"], [\"f\"]],\n",
      "    }\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      serialized: A vector (1-D Tensor) of strings, a batch of binary\n",
      "        serialized `Example` protos.\n",
      "      features: A `dict` mapping feature keys to `FixedLenFeature` or\n",
      "        `VarLenFeature` values.\n",
      "      name: A name for this operation (optional).\n",
      "      example_names: A vector (1-D Tensor) of strings (optional), the names of\n",
      "        the serialized protos in the batch.\n",
      "    \n",
      "    Returns:\n",
      "      A `dict` mapping feature keys to `Tensor` and `SparseTensor` values.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: if any feature is invalid.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.parse_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method randint in module random:\n",
      "\n",
      "randint(self, a, b) method of random.Random instance\n",
      "    Return random integer in range [a, b], including both end points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(random.randint)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def f(n):\n",
    "    n.value += 1\n",
    "name = 'main'\n",
    "if name == 'main':\n",
    "    print 'abc'\n",
    "    d = {}\n",
    "    p = []\n",
    "\n",
    "    for i in range(5):\n",
    "        d[i] = Manager().Value('i',0)\n",
    "        p.append(Process(target=f, args=(d[i],)))\n",
    "        p[i].start()\n",
    "\n",
    "    for q in p:\n",
    "        q.join()\n",
    "\n",
    "    for i in d:\n",
    "        d[i] = d[i].value\n",
    "\n",
    "    print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "print 'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(n):\n",
    "    n.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    d[i] = Manager().Value('i',0)\n",
    "    p.append(Process(target=f, args=(d[i],)))\n",
    "    p[i].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " for q in p:\n",
    "        q.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   for i in d:\n",
    "        d[i] = d[i].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}\n"
     ]
    }
   ],
   "source": [
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Manager in module multiprocessing:\n",
      "\n",
      "Manager()\n",
      "    Returns a manager associated with a running server process\n",
      "    \n",
      "    The managers methods such as `Lock()`, `Condition()` and `Queue()`\n",
      "    can be used to create shared objects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Array in module multiprocessing.managers:\n",
      "\n",
      "Array(self, *args, **kwds) method of multiprocessing.managers.SyncManager instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(m.Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = m.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DictProxy in module multiprocessing.managers object:\n",
      "\n",
      "class DictProxy(BaseProxy)\n",
      " |  Method resolution order:\n",
      " |      DictProxy\n",
      " |      BaseProxy\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, *args, **kwds)\n",
      " |  \n",
      " |  __delitem__(self, *args, **kwds)\n",
      " |  \n",
      " |  __getitem__(self, *args, **kwds)\n",
      " |  \n",
      " |  __len__(self, *args, **kwds)\n",
      " |  \n",
      " |  __setitem__(self, *args, **kwds)\n",
      " |  \n",
      " |  clear(self, *args, **kwds)\n",
      " |  \n",
      " |  copy(self, *args, **kwds)\n",
      " |  \n",
      " |  get(self, *args, **kwds)\n",
      " |  \n",
      " |  has_key(self, *args, **kwds)\n",
      " |  \n",
      " |  items(self, *args, **kwds)\n",
      " |  \n",
      " |  keys(self, *args, **kwds)\n",
      " |  \n",
      " |  pop(self, *args, **kwds)\n",
      " |  \n",
      " |  popitem(self, *args, **kwds)\n",
      " |  \n",
      " |  setdefault(self, *args, **kwds)\n",
      " |  \n",
      " |  update(self, *args, **kwds)\n",
      " |  \n",
      " |  values(self, *args, **kwds)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseProxy:\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __init__(self, token, serializer, manager=None, authkey=None, exposed=None, incref=True)\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return representation of the referent (or a fall-back if that fails)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseProxy:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d[3] =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print d[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print d.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d[4] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "print d.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x5f02a90>> ignored\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "a = tf.constant([[[0, 0, 1], [0,1,1]],[[1, 0, 1], [1, 1, 1]]])\n",
    "b = tf.constant([[0, 0, 2], [1, 0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.eval().shape\n",
    "tf.shape(b)[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n",
      "3\n",
      "[[[3 3 3]\n",
      "  [4 4 4]]]\n",
      "[[[3 3 3]]\n",
      "\n",
      " [[5 5 5]]]\n"
     ]
    }
   ],
   "source": [
    "input =  tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "            [[3, 3, 3], [4, 4, 4]],\n",
    "             [[5, 5, 5], [6, 6, 6]]])\n",
    "print input.eval().shape\n",
    "print tf.shape(input)[2].eval()\n",
    "#print tf.slice(input, [1, 0, 0], [1, 1, tf.shape(input)[2]]).eval() \n",
    "print tf.slice(input, [1, 0, 0], [1, 2, -1]).eval()\n",
    "                                           \n",
    "print tf.slice(input, [1, 0, 0], [2, 1, -1]).eval()\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b2 = tf.slice(b, [0, 0], [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 2]\n",
      " [1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "print b2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2 = tf.slice(a, [0, 0, 0], [1, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 1]]]\n"
     ]
    }
   ],
   "source": [
    "print a2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print b2.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 3]]]\n"
     ]
    }
   ],
   "source": [
    "print (b2 + a2).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(input, b2).eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1],\n",
       "        [2, 2, 2]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [2, 2, 2]],\n",
       "\n",
       "       [[5, 5, 5],\n",
       "        [6, 6, 6]]], dtype=int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(input, tf.reshape(b2, [3,])).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(b2, [3,]).eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5,  1.5,  1.5],\n",
       "       [ 1.5,  1.5,  1.5],\n",
       "       [ 5.5,  5.5,  5.5]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.cast(tf.nn.embedding_lookup(input, tf.reshape(b2, [3,])), tf.float32), 1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cast in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "cast(x, dtype, name=None)\n",
      "    Casts a tensor to a new type.\n",
      "    \n",
      "    The operation casts `x` (in case of `Tensor`) or `x.values`\n",
      "    (in case of `SparseTensor`) to `dtype`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # tensor `a` is [1.8, 2.2], dtype=tf.float\n",
      "    tf.cast(a, tf.int32) ==> [1, 2]  # dtype=tf.int32\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      x: A `Tensor` or `SparseTensor`.\n",
      "      dtype: The destination type.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` or `SparseTensor` with same shape as `x`.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If `x` cannot be cast to the `dtype`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 7, 9],\n",
       "       [5, 5, 5]], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[[1,2,3], [4, 5, 6]],[[2,2,2], [3,3,3]]])\n",
    "tf.reduce_sum(a, 1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]\n",
      " [4 4 4]]\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,1,1], [2,2,2], [3,3,3], [4,4,4]])\n",
    "print x.eval()\n",
    "print x.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(x, b2).eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 2]\n",
      " [1 0 2]]\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "b = tf.constant([[0, 0, 2], [1, 0, 2], [0, 0, 0]])\n",
    "b = tf.slice(b, [0, 0], [2, 3])\n",
    "print b.eval()\n",
    "print b.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [3, 3, 3]],\n",
       "\n",
       "       [[2, 2, 2],\n",
       "        [1, 1, 1],\n",
       "        [3, 3, 3]]], dtype=int32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(x, b).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(x, b).eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = tf.cast(tf.nn.embedding_lookup(x, b), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.reduce_mean(u, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.66666663,  1.66666663,  1.66666663],\n",
       "       [ 2.        ,  2.        ,  2.        ]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = tf.constant([[[0, 0, 2], [1, 0, 2]], [[0, 0, 0], [1,1,1]], [[0, 0, 0], [1,1,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [3, 3, 3]],\n",
       "\n",
       "        [[2, 2, 2],\n",
       "         [1, 1, 1],\n",
       "         [3, 3, 3]]],\n",
       "\n",
       "\n",
       "       [[[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [1, 1, 1]],\n",
       "\n",
       "        [[2, 2, 2],\n",
       "         [2, 2, 2],\n",
       "         [2, 2, 2]]],\n",
       "\n",
       "\n",
       "       [[[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [1, 1, 1]],\n",
       "\n",
       "        [[2, 2, 2],\n",
       "         [2, 2, 2],\n",
       "         [2, 2, 2]]]], dtype=int32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(x, c).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 3, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.cast(tf.nn.embedding_lookup(x, c), tf.float32)\n",
    "u.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.reduce_mean(u, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.66666663,  1.66666663,  1.66666663],\n",
       "        [ 2.        ,  2.        ,  2.        ]],\n",
       "\n",
       "       [[ 1.        ,  1.        ,  1.        ],\n",
       "        [ 2.        ,  2.        ,  2.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_sum in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_sum(input_tensor, reduction_indices=None, keep_dims=False, name=None)\n",
      "    Computes the sum of elements across dimensions of a tensor.\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `reduction_indices`.\n",
      "    Unless `keep_dims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    entry in `reduction_indices`. If `keep_dims` is true, the reduced dimensions\n",
      "    are retained with length 1.\n",
      "    \n",
      "    If `reduction_indices` has no entries, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # 'x' is [[1, 1, 1]\n",
      "    #         [1, 1, 1]]\n",
      "    tf.reduce_sum(x) ==> 6\n",
      "    tf.reduce_sum(x, 0) ==> [2, 2, 2]\n",
      "    tf.reduce_sum(x, 1) ==> [3, 3]\n",
      "    tf.reduce_sum(x, 1, keep_dims=True) ==> [[3], [3]]\n",
      "    tf.reduce_sum(x, [0, 1]) ==> 6\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      reduction_indices: The dimensions to reduce. If `None` (the default),\n",
      "        reduces all dimensions.\n",
      "      keep_dims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reduce_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'Sqrt' with these attrs\n\t [[Node: Sqrt_3 = Sqrt[T=DT_INT32](Sum_9)]]\nCaused by op u'Sqrt_3', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-125-3a778d29c483>\", line 1, in <module>\n    norm = tf.sqrt(tf.reduce_sum(tf.square(tf.constant([[1,2,3]])), 0, keep_dims=True))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1664, in sqrt\n    return _op_def_lib.apply_op(\"Sqrt\", x=x, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-3a778d29c483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \"\"\"\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3374\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3375\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3376\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 332\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    333\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 572\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    573\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 652\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    653\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'Sqrt' with these attrs\n\t [[Node: Sqrt_3 = Sqrt[T=DT_INT32](Sum_9)]]\nCaused by op u'Sqrt_3', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-125-3a778d29c483>\", line 1, in <module>\n    norm = tf.sqrt(tf.reduce_sum(tf.square(tf.constant([[1,2,3]])), 0, keep_dims=True))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1664, in sqrt\n    return _op_def_lib.apply_op(\"Sqrt\", x=x, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "norm = tf.sqrt(tf.reduce_sum(tf.square(tf.constant([[1,2,3]])), 0, keep_dims=True))\n",
    "norm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14],\n",
       "       [26]], dtype=int32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1,2, 3],[3,4,5]])\n",
    "print x.eval().shape\n",
    "y = tf.constant([[1], [2], [3]])\n",
    "print y.eval().shape\n",
    "z = tf.matmul(x, y)\n",
    "z.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n",
      "(3, 2)\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[3 4 5]]]\n",
      "z: [[14 15]\n",
      " [26 29]]\n",
      "[[[1 2 4]]\n",
      "\n",
      " [[4 5 6]]]\n",
      "z: [[17 18]\n",
      " [32 36]]\n",
      "[[14 15]\n",
      " [26 29]\n",
      " [17 18]\n",
      " [32 36]]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[1,2, 3],[1,2,4]], [[3,4,5],[4,5,6]]])\n",
    "print x.eval().shape\n",
    "y = tf.constant([[1, 2], [2, 2], [3, 3]])\n",
    "print y.eval().shape\n",
    "#z = tf.matmul(x, y)\n",
    "#z.eval()\n",
    "#u = tf.constant([[0], [0]])\n",
    "#u = None\n",
    "l = []\n",
    "for i in range(2):\n",
    "    print tf.slice(x, [0, i, 0], [2, 1, 3]).eval()\n",
    "    z = tf.matmul(tf.reshape(tf.slice(x, [0, i, 0], [2, 1, 3]), [2, 3]), y)\n",
    "    print 'z:', z.eval()\n",
    "    #u += z\n",
    "    #if u == None:\n",
    "    #    u = z\n",
    "    #else:\n",
    "    #    u = tf.concat(1, [u, z])\n",
    "    #print 'u:', u.eval()\n",
    "    l.append(z)\n",
    "\n",
    "u = tf.concat(0, l)\n",
    "print u.eval()\n",
    "print u.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 15]\n",
      " [26 29]]\n",
      "[[17 18]\n",
      " [32 36]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print tf.slice(u, [0, i * 2], [2, 2]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 15 17 18]\n"
     ]
    }
   ],
   "source": [
    "print tf.unpack(u)[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function unpack in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "unpack(value, num=None, name='unpack')\n",
      "    Unpacks the outer dimension of a rank-`R` tensor into rank-`(R-1)` tensors.\n",
      "    \n",
      "    Unpacks `num` tensors from `value` along the first dimension.\n",
      "    If `num` is not specified (the default), it is inferred from `value`'s shape.\n",
      "    If `value.shape[0]` is not known, `ValueError` is raised.\n",
      "    \n",
      "    The ith tensor in `output` is the slice `value[i, ...]`. Each tensor in\n",
      "    `output` has shape `value.shape[1:]`.\n",
      "    \n",
      "    This is the opposite of pack.  The numpy equivalent is\n",
      "    \n",
      "        tf.unpack(x, n) = list(x)\n",
      "    \n",
      "    Args:\n",
      "      value: A rank `R > 0` `Tensor` to be unpacked.\n",
      "      num: An `int`. The first dimension of value. Automatically inferred if\n",
      "        `None` (the default).\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The list of `Tensor` objects unpacked from `value`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `num` is unspecified and cannot be inferred.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.unpack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5]\n",
      " [ 1. ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "B = 2\n",
    "N = 2\n",
    "scores = tf.constant([0.5, 0.2, -0.1, 1., -0.5, 0.3])  # shape B * (N+1)\n",
    "\n",
    "scores = tf.reshape(scores, [B, N+1])\n",
    "\n",
    "scores_pos = tf.slice(scores, [0, 0], [B, 1])\n",
    "\n",
    "scores_neg = tf.slice(scores, [0, 1], [B, N])\n",
    "\n",
    "print scores_pos.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [3 4 5]\n",
      " [4 5 6]]\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[2 3]\n",
      " [2 3]\n",
      " [2 3]\n",
      " [2 3]]\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "s = tf.constant([1,2, 3, 4])\n",
    "s2 = tf.constant([2, 3, 4, 5])\n",
    "s3 = tf.constant([3, 4, 5, 6])\n",
    "a = tf.reshape(s, [4,1])\n",
    "b = tf.reshape(s2, [4, 1])\n",
    "c = tf.reshape(s3, [4, 1])\n",
    "x = tf.concat(1,[a, b, c])\n",
    "print x.eval()\n",
    "\n",
    "scores_pos = tf.slice(x, [0, 0], [4, 1])\n",
    "print scores_pos.eval()\n",
    "scores_neg = tf.slice(x, [0, 1], [4, 2])\n",
    "loss_matrix = tf.maximum(0, 1 - scores_pos + scores_neg)  # we could also use tf.nn.relu here\n",
    "print loss_matrix.eval()\n",
    "#loss = tf.reduce_mean(tf.reduce_sum(loss_matrix, 1))\n",
    "loss = tf.reduce_mean(tf.cast(loss_matrix, tf.float32))\n",
    "print loss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.reshape(x, [4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 2, 3],\n",
       "       [4, 5, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_matrix = tf.maximum(0., 1. - scores_pos + scores_neg)  # we could also use tf.nn.relu here\n",
    "loss = tf.reduce_sum(loss_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3], [4,5,6]])\n",
    "b = tf.constant([[1,1,1], [2,2,2]])\n",
    "print a.eval().shape\n",
    "print b.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'Sqrt' with these attrs\n\t [[Node: Sqrt_4 = Sqrt[T=DT_INT32](Sum_15)]]\nCaused by op u'Sqrt_4', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-193-d1cf0847badf>\", line 1, in <module>\n    a = tf.sqrt(tf.reduce_sum(tf.square(a), 1, keep_dims=True))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1664, in sqrt\n    return _op_def_lib.apply_op(\"Sqrt\", x=x, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-cd94b962c256>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnorm_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mnorm_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \"\"\"\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3374\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3375\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3376\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 332\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    333\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 572\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    573\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 652\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    653\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'Sqrt' with these attrs\n\t [[Node: Sqrt_4 = Sqrt[T=DT_INT32](Sum_15)]]\nCaused by op u'Sqrt_4', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-193-d1cf0847badf>\", line 1, in <module>\n    a = tf.sqrt(tf.reduce_sum(tf.square(a), 1, keep_dims=True))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1664, in sqrt\n    return _op_def_lib.apply_op(\"Sqrt\", x=x, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 693, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2177, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1161, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "norm_a = tf.sqrt(tf.reduce_sum(tf.square(a), 1, keep_dims=True))\n",
    "print norm_a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
