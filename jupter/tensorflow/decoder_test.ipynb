{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_length = [3, 4, 3, 1, 0]\n",
    "batch_size = 5\n",
    "max_time = 8\n",
    "input_depth = 7\n",
    "cell_depth = 10\n",
    "max_out = max(sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -1.63054931e+00,   4.56274897e-01,  -6.83186412e-01,\n",
       "          -1.53135717e+00,   9.34157789e-01,  -3.99784036e-02,\n",
       "          -6.25981092e-01],\n",
       "        [  2.29047582e-01,   3.22035164e-01,  -7.21430242e-01,\n",
       "          -5.32526672e-01,  -1.24769616e+00,   1.15178835e+00,\n",
       "          -1.41922069e+00],\n",
       "        [ -7.27448583e-01,  -1.41406834e+00,  -7.90897757e-02,\n",
       "           2.60723799e-01,  -1.00787592e+00,  -1.44772291e-01,\n",
       "          -2.69150082e-02],\n",
       "        [ -1.21435535e+00,  -4.91854787e-01,   2.48019919e-01,\n",
       "           3.17332000e-01,   2.45850340e-01,   6.85159326e-01,\n",
       "          -2.48433605e-01],\n",
       "        [  6.08725607e-01,   4.89112556e-01,  -7.40392148e-01,\n",
       "          -7.26322711e-01,  -1.24961877e+00,   7.94758022e-01,\n",
       "          -4.07460570e-01]],\n",
       "\n",
       "       [[  8.10555160e-01,   7.84145951e-01,   1.07380617e+00,\n",
       "           3.41595896e-02,  -2.10963845e+00,   3.98175985e-01,\n",
       "           4.18650508e-02],\n",
       "        [  3.23609382e-01,   9.17592719e-02,   9.60837483e-01,\n",
       "          -1.92185596e-01,   6.00126863e-01,  -5.12152910e-01,\n",
       "          -9.51412320e-01],\n",
       "        [ -1.02854691e-01,  -7.80596673e-01,  -2.85746694e-01,\n",
       "           1.61062539e+00,  -2.02094531e+00,   1.82172135e-01,\n",
       "          -4.22613531e-01],\n",
       "        [  1.18038917e+00,   1.16762593e-01,   5.71890771e-01,\n",
       "          -9.48025048e-01,  -1.25207865e+00,   4.94320035e-01,\n",
       "          -2.00372070e-01],\n",
       "        [  6.41327649e-02,  -2.39794755e+00,   2.93342233e-01,\n",
       "          -5.26053980e-02,  -1.08040082e+00,  -1.65944174e-01,\n",
       "           2.46016860e-01]],\n",
       "\n",
       "       [[  3.34001899e-01,   1.44014224e-01,   4.30943929e-02,\n",
       "           1.11468577e+00,   3.89973611e-01,   3.86766016e-01,\n",
       "          -1.75266206e-01],\n",
       "        [  4.34704721e-01,  -7.12553382e-01,   1.08090544e+00,\n",
       "           3.45343053e-01,   3.57959539e-01,  -5.48565805e-01,\n",
       "           1.71765113e+00],\n",
       "        [  7.26177514e-01,   1.32845223e+00,  -2.03007415e-01,\n",
       "          -1.61745894e+00,  -2.70766854e-01,  -6.95466399e-01,\n",
       "           5.80570698e-01],\n",
       "        [ -9.88610685e-01,   1.73705554e+00,  -5.16590774e-01,\n",
       "          -8.59526277e-01,   1.27273917e+00,   2.08291817e+00,\n",
       "          -9.29967999e-01],\n",
       "        [ -1.28975260e+00,   7.41891712e-02,  -4.94426072e-01,\n",
       "          -3.44241768e-01,  -6.89805567e-01,   1.02615941e+00,\n",
       "           5.24016440e-01]],\n",
       "\n",
       "       [[  5.55478156e-01,   3.07349056e-01,  -1.59987569e+00,\n",
       "          -1.06670260e+00,   1.56486046e+00,   1.56133020e+00,\n",
       "          -5.04729033e-01],\n",
       "        [ -2.72727895e+00,  -1.13931680e+00,   1.18815672e+00,\n",
       "          -1.50149167e+00,  -1.09554939e-01,  -6.74616158e-01,\n",
       "          -1.56835824e-01],\n",
       "        [ -1.75453496e+00,  -1.83688119e-01,   2.36074448e+00,\n",
       "          -7.01967657e-01,  -7.07451031e-02,  -6.09655678e-01,\n",
       "          -9.45638299e-01],\n",
       "        [  1.16678333e+00,  -2.09085383e-02,  -1.76104975e+00,\n",
       "          -8.60434353e-01,   4.96053278e-01,  -3.43627453e-01,\n",
       "          -1.42335400e-01],\n",
       "        [ -6.82918847e-01,   1.50144324e-01,   4.55158770e-01,\n",
       "          -1.15413594e+00,   8.67380738e-01,  -4.88372415e-01,\n",
       "           6.70184135e-01]],\n",
       "\n",
       "       [[  5.83641887e-01,   6.60259798e-02,   1.93484521e+00,\n",
       "          -6.74109086e-02,  -1.42407107e+00,  -2.95899343e-02,\n",
       "           5.71100056e-01],\n",
       "        [  9.84372437e-01,  -2.29976225e+00,   2.04377621e-01,\n",
       "          -2.46625805e+00,   1.46213830e+00,   1.47223258e+00,\n",
       "           5.09943187e-01],\n",
       "        [ -8.36512029e-01,  -2.10724926e+00,   2.18966222e+00,\n",
       "           3.45318437e-01,   1.17286026e+00,  -8.66920501e-02,\n",
       "           1.13484836e+00],\n",
       "        [  1.80209607e-01,   6.86005235e-01,   1.88995734e-01,\n",
       "           6.21224456e-02,   1.43040168e+00,  -1.36984897e+00,\n",
       "           2.15288448e+00],\n",
       "        [ -2.97303736e-01,  -3.26899827e-01,   1.63796484e+00,\n",
       "          -3.87345374e-01,  -1.47209930e+00,   4.53241587e-01,\n",
       "          -2.67707795e-01]],\n",
       "\n",
       "       [[  4.28738981e-01,  -2.34804487e+00,  -1.65299788e-01,\n",
       "          -2.20436430e+00,  -2.35246807e-01,   1.46981537e-01,\n",
       "           6.00384355e-01],\n",
       "        [  1.10725760e+00,  -2.22507691e+00,   1.67025959e+00,\n",
       "           8.86410177e-01,   5.19687593e-01,  -1.80337167e+00,\n",
       "           1.00305593e+00],\n",
       "        [  9.05606151e-01,  -1.18179631e+00,  -4.96796817e-01,\n",
       "           1.12099791e+00,   1.15921155e-01,   5.06352365e-01,\n",
       "           8.84638250e-01],\n",
       "        [  1.07403314e+00,  -1.35535896e-01,  -8.73416960e-01,\n",
       "           1.99581182e+00,   1.00068545e+00,  -1.42274368e+00,\n",
       "           1.15906882e+00],\n",
       "        [  1.42732501e+00,  -1.39963412e+00,  -1.23769641e+00,\n",
       "           4.91559394e-02,   8.05816129e-02,  -1.17560171e-01,\n",
       "           2.85331327e-02]],\n",
       "\n",
       "       [[  1.38365233e+00,   1.28266215e+00,  -1.53282654e+00,\n",
       "          -1.55113089e+00,  -1.08954525e+00,  -5.75204454e-02,\n",
       "           3.00856566e+00],\n",
       "        [ -2.01686129e-01,  -1.64046273e-01,   1.80592370e+00,\n",
       "           2.51170844e-01,  -9.73541856e-01,  -3.49998236e-01,\n",
       "          -2.86634326e-01],\n",
       "        [  1.34862578e+00,  -1.02399886e+00,   4.95977104e-02,\n",
       "          -8.21843147e-01,  -1.07981706e+00,  -8.27647328e-01,\n",
       "          -1.96948752e-01],\n",
       "        [  1.78498995e+00,   4.67344344e-01,  -1.18549719e-01,\n",
       "           1.22413933e-01,   1.18820632e+00,   2.27619382e-03,\n",
       "           3.29672277e-01],\n",
       "        [ -2.32094169e+00,   1.15363998e-02,   4.73211020e-01,\n",
       "           2.87264854e-01,   9.54168439e-01,   2.04329520e-01,\n",
       "          -2.75380945e+00]],\n",
       "\n",
       "       [[  1.37925193e-01,   1.66770911e+00,   2.19124269e+00,\n",
       "          -5.10166109e-01,   9.96867478e-01,   1.76268172e+00,\n",
       "           1.88533998e+00],\n",
       "        [  1.31990552e+00,   5.89503706e-01,  -1.52749979e+00,\n",
       "           4.12692934e-01,   4.04693931e-01,   4.17513996e-01,\n",
       "           8.46309721e-01],\n",
       "        [  2.91732579e-01,  -1.76017773e+00,  -6.21095836e-01,\n",
       "          -6.63164735e-01,   4.18281883e-01,   3.80768716e-01,\n",
       "           3.43948841e-01],\n",
       "        [ -7.82174885e-01,   2.46541548e+00,  -8.66069138e-01,\n",
       "           1.17914689e+00,  -8.87182504e-02,  -8.95387650e-01,\n",
       "           1.38839793e+00],\n",
       "        [ -2.44864416e+00,   9.52737927e-01,   1.69669062e-01,\n",
       "          -1.02566195e+00,   5.47849596e-01,  -3.67533565e-01,\n",
       "           1.13364804e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_major = True\n",
    "if time_major:\n",
    "  inputs = np.random.randn(max_time, batch_size,\n",
    "                           input_depth).astype(np.float32)\n",
    "else:\n",
    "  inputs = np.random.randn(batch_size, max_time,\n",
    "                           input_depth).astype(np.float32)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "\n",
    "import six\n",
    "\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "__all__ = [\"Decoder\", \"dynamic_decode_rnn\"]\n",
    "\n",
    "\n",
    "def _transpose_batch_time(x):\n",
    "  \"\"\"Transpose the batch and time dimensions of a Tensor.\n",
    "\n",
    "  Retains as much of the static shape information as possible.\n",
    "\n",
    "  Args:\n",
    "    x: A tensor of rank 2 or higher.\n",
    "\n",
    "  Returns:\n",
    "    x transposed along the first two dimensions.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if `x` is rank 1 or lower.\n",
    "  \"\"\"\n",
    "  x_static_shape = x.get_shape()\n",
    "  if x_static_shape.ndims is not None and x_static_shape.ndims < 2:\n",
    "    raise ValueError(\n",
    "        \"Expected input tensor %s to have rank at least 2, but saw shape: %s\" %\n",
    "        (x, x_static_shape))\n",
    "  x_rank = array_ops.rank(x)\n",
    "  x_t = array_ops.transpose(\n",
    "      x, array_ops.concat_v2(\n",
    "          ([1, 0], math_ops.range(2, x_rank)), axis=0))\n",
    "  x_t.set_shape(\n",
    "      tensor_shape.TensorShape([\n",
    "          x_static_shape[1].value, x_static_shape[0].value\n",
    "      ]).concatenate(x_static_shape[2:]))\n",
    "  return x_t\n",
    "\n",
    "\n",
    "@six.add_metaclass(abc.ABCMeta)\n",
    "class Decoder(object):\n",
    "  \"\"\"An RNN Decoder abstract interface object.\"\"\"\n",
    "\n",
    "  @property\n",
    "  def batch_size(self):\n",
    "    \"\"\"The batch size of the inputs returned by `sample`.\"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    \"\"\"A (possibly nested tuple of...) integer[s] or `TensorShape` object[s].\"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "  @property\n",
    "  def output_dtype(self):\n",
    "    \"\"\"A (possibly nested tuple of...) dtype[s].\"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def initialize(self, name=None):\n",
    "    \"\"\"Called before any decoding iterations.\n",
    "\n",
    "    Args:\n",
    "      name: Name scope for any created operations.\n",
    "\n",
    "    Returns:\n",
    "      `(finished, first_inputs, initial_state)`.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def step(self, time, inputs, state):\n",
    "    \"\"\"Called per step of decoding (but only once for dynamic decoding).\n",
    "\n",
    "    Args:\n",
    "      time: Scalar `int32` tensor.\n",
    "      inputs: Input (possibly nested tuple of) tensor[s] for this time step.\n",
    "      state: State (possibly nested tuple of) tensor[s] from previous time step.\n",
    "\n",
    "    Returns:\n",
    "      `(outputs, next_state, next_inputs, finished)`.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def _create_zero_outputs(size, dtype, batch_size):\n",
    "  \"\"\"Create a zero outputs Tensor structure.\"\"\"\n",
    "  def _t(s):\n",
    "    return (s if isinstance(s, ops.Tensor) else constant_op.constant(\n",
    "        tensor_shape.TensorShape(s).as_list(),\n",
    "        dtype=dtypes.int32,\n",
    "        name=\"zero_suffix_shape\"))\n",
    "\n",
    "  def _create(s, d):\n",
    "    return array_ops.zeros(\n",
    "        array_ops.concat(\n",
    "            ([batch_size], _t(s)), axis=0), dtype=d)\n",
    "\n",
    "  return nest.map_structure(_create, size, dtype)\n",
    "\n",
    "\n",
    "def dynamic_decode_rnn(decoder,\n",
    "                       output_time_major=False,\n",
    "                       parallel_iterations=32,\n",
    "                       swap_memory=False):\n",
    "  \"\"\"Perform dynamic decoding with `decoder`.\n",
    "\n",
    "  Args:\n",
    "    decoder: A `Decoder` instance.\n",
    "    output_time_major: Python boolean.  Default: `False` (batch major).  If\n",
    "      `True`, outputs are returned as time major tensors (this mode is faster).\n",
    "      Otherwise, outputs are returned as batch major tensors (this adds extra\n",
    "      time to the computation).\n",
    "    parallel_iterations: Argument passed to `tf.while_loop`.\n",
    "    swap_memory: Argument passed to `tf.while_loop`.\n",
    "\n",
    "  Returns:\n",
    "    `(final_outputs, final_state)`.\n",
    "\n",
    "  Raises:\n",
    "    TypeError: if `decoder` is not an instance of `Decoder`.\n",
    "  \"\"\"\n",
    "  if not isinstance(decoder, Decoder):\n",
    "    raise TypeError(\"Expected decoder to be type Decoder, but saw: %s\" %\n",
    "                    type(decoder))\n",
    "\n",
    "  zero_outputs = _create_zero_outputs(decoder.output_size, decoder.output_dtype,\n",
    "                                      decoder.batch_size)\n",
    "\n",
    "  initial_finished, initial_inputs, initial_state = decoder.initialize()\n",
    "  initial_time = constant_op.constant(0, dtype=dtypes.int32)\n",
    "\n",
    "  def _shape(batch_size, from_shape):\n",
    "    if not isinstance(from_shape, tensor_shape.TensorShape):\n",
    "      return tensor_shape.TensorShape(None)\n",
    "    else:\n",
    "      batch_size = tensor_util.constant_value(\n",
    "          ops.convert_to_tensor(\n",
    "              batch_size, name=\"batch_size\"))\n",
    "      return tensor_shape.TensorShape([batch_size]).concatenate(from_shape)\n",
    "\n",
    "  def _create_ta(s, d):\n",
    "    return tensor_array_ops.TensorArray(\n",
    "        dtype=d, size=0, dynamic_size=True,\n",
    "        element_shape=_shape(decoder.batch_size, s))\n",
    "\n",
    "  initial_outputs_ta = nest.map_structure(\n",
    "      _create_ta, decoder.output_size, decoder.output_dtype)\n",
    "\n",
    "  def condition(unused_time, unused_outputs_ta, unused_state, unused_inputs,\n",
    "                finished):\n",
    "    return math_ops.logical_not(math_ops.reduce_all(finished))\n",
    "\n",
    "  def body(time, outputs_ta, state, inputs, finished):\n",
    "    \"\"\"Internal while_loop body.\n",
    "\n",
    "    Args:\n",
    "      time: scalar int32 tensor.\n",
    "      outputs_ta: structure of TensorArray.\n",
    "      state: (structure of) state tensors and TensorArrays.\n",
    "      inputs: (structure of) input tensors.\n",
    "      finished: 1-D bool tensor.\n",
    "\n",
    "    Returns:\n",
    "      `(time + 1, outputs_ta, next_state, next_inputs, next_finished)`.\n",
    "    \"\"\"\n",
    "    (next_outputs, decoder_state, next_inputs, decoder_finished) = decoder.step(\n",
    "        time, inputs, state)\n",
    "    next_finished = math_ops.logical_or(decoder_finished, finished)\n",
    "\n",
    "    nest.assert_same_structure(state, decoder_state)\n",
    "    nest.assert_same_structure(outputs_ta, next_outputs)\n",
    "    nest.assert_same_structure(inputs, next_inputs)\n",
    "\n",
    "    # Zero out output values past finish\n",
    "    emit = nest.map_structure(\n",
    "        lambda out, zero: array_ops.where(finished, zero, out), next_outputs,\n",
    "        zero_outputs)\n",
    "\n",
    "    # Copy through states past finish\n",
    "    def _maybe_copy_state(new, cur):\n",
    "      return (new if isinstance(cur, tensor_array_ops.TensorArray) else\n",
    "              array_ops.where(finished, cur, new))\n",
    "\n",
    "    next_state = nest.map_structure(_maybe_copy_state, decoder_state, state)\n",
    "    outputs_ta = nest.map_structure(lambda ta, out: ta.write(time, out),\n",
    "                                    outputs_ta, emit)\n",
    "    return (time + 1, outputs_ta, next_state, next_inputs, next_finished)\n",
    "\n",
    "  res = control_flow_ops.while_loop(\n",
    "      condition,\n",
    "      body,\n",
    "      loop_vars=[\n",
    "          initial_time, initial_outputs_ta, initial_state, initial_inputs,\n",
    "          initial_finished\n",
    "      ],\n",
    "      parallel_iterations=parallel_iterations,\n",
    "      swap_memory=swap_memory)\n",
    "\n",
    "  final_outputs_ta = res[1]\n",
    "  final_state = res[2]\n",
    "\n",
    "  final_outputs = nest.map_structure(lambda ta: ta.stack(), final_outputs_ta)\n",
    "  if not output_time_major:\n",
    "    final_outputs = nest.map_structure(_transpose_batch_time, final_outputs)\n",
    "\n",
    "  return final_outputs, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import collections\n",
    "\n",
    "import six\n",
    "\n",
    "from tensorflow.contrib.rnn import core_rnn_cell\n",
    "from tensorflow.contrib.seq2seq.python.ops import decoder\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "__all__ = [\n",
    "    \"Sampler\", \"SamplingDecoderOutput\", \"BasicSamplingDecoder\",\n",
    "    \"BasicTrainingSampler\"\n",
    "]\n",
    "\n",
    "_transpose_batch_time = decoder._transpose_batch_time  # pylint: disable=protected-access\n",
    "@six.add_metaclass(abc.ABCMeta)\n",
    "class Sampler(object):\n",
    "\n",
    "  @property\n",
    "  def batch_size(self):\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def initialize(self):\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def sample(self, time, outputs, state):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SamplingDecoderOutput(\n",
    "    collections.namedtuple(\"SamplingDecoderOutput\",\n",
    "                           (\"rnn_output\", \"sample_id\"))):\n",
    "  pass\n",
    "\n",
    "\n",
    "class BasicSamplingDecoder(Decoder):\n",
    "  \"\"\"Basic sampling decoder.\"\"\"\n",
    "\n",
    "  def __init__(self, cell, sampler, initial_state):\n",
    "    \"\"\"Initialize BasicSamplingDecoder.\n",
    "\n",
    "    Args:\n",
    "      cell: An `RNNCell` instance.\n",
    "      sampler: A `Sampler` instance.\n",
    "      initial_state: A (possibly nested tuple of...) tensors and TensorArrays.\n",
    "\n",
    "    Raises:\n",
    "      TypeError: if `cell` is not an instance of `RNNCell` or `sampler`\n",
    "        is not an instance of `Sampler`.\n",
    "    \"\"\"\n",
    "    if not isinstance(cell, core_rnn_cell.RNNCell):\n",
    "      raise TypeError(\"cell must be an RNNCell, received: %s\" % type(cell))\n",
    "    if not isinstance(sampler, Sampler):\n",
    "      raise TypeError(\"sampler must be a Sampler, received: %s\" %\n",
    "                      type(sampler))\n",
    "    self._cell = cell\n",
    "    self._sampler = sampler\n",
    "    self._initial_state = initial_state\n",
    "\n",
    "  @property\n",
    "  def batch_size(self):\n",
    "    return self._sampler.batch_size\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    # Return the cell output and the id\n",
    "    return SamplingDecoderOutput(\n",
    "        rnn_output=self._cell.output_size,\n",
    "        sample_id=tensor_shape.TensorShape([]))\n",
    "\n",
    "  @property\n",
    "  def output_dtype(self):\n",
    "    # Assume the dtype of the cell is the output_size structure\n",
    "    # containing the input_state's first component's dtype.\n",
    "    # Return that structure and int32 (the id)\n",
    "    dtype = nest.flatten(self._initial_state)[0].dtype\n",
    "    return SamplingDecoderOutput(\n",
    "        nest.map_structure(lambda _: dtype, self._cell.output_size),\n",
    "        dtypes.int32)\n",
    "\n",
    "  def initialize(self, name=None):\n",
    "    return self._sampler.initialize() + (self._initial_state,)\n",
    "\n",
    "  def step(self, time, inputs, state):\n",
    "    \"\"\"Perform a decoding step.\n",
    "\n",
    "    Args:\n",
    "      time: scalar `int32` tensor.\n",
    "      inputs: A (structure of) input tensors.\n",
    "      state: A (structure of) state tensors and TensorArrays.\n",
    "\n",
    "    Returns:\n",
    "      `(outputs, next_state, next_inputs, finished)`.\n",
    "    \"\"\"\n",
    "    cell_outputs, next_state = self._cell(inputs, state)\n",
    "    (sample_id, finished, next_inputs) = self._sampler.sample(\n",
    "        time=time, outputs=cell_outputs, state=next_state)\n",
    "    outputs = SamplingDecoderOutput(cell_outputs, sample_id)\n",
    "    return (outputs, next_state, next_inputs, finished)\n",
    "\n",
    "class BasicTrainingSampler(Sampler):\n",
    "  \"\"\"A (non-)sampler for use during training.  Only reads inputs.\"\"\"\n",
    "\n",
    "  def __init__(self, inputs, sequence_length, time_major=False):\n",
    "    \"\"\"Initializer.\n",
    "\n",
    "    Args:\n",
    "      inputs: A (structure of) input tensors.\n",
    "      sequence_length: An int32 vector tensor.\n",
    "      time_major: Python bool.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if `sequence_length` is not a 1D tensor.\n",
    "    \"\"\"\n",
    "    inputs = ops.convert_to_tensor(inputs, name=\"inputs\")\n",
    "    if not time_major:\n",
    "      inputs = nest.map_structure(_transpose_batch_time, inputs)\n",
    "\n",
    "    def _unstack_ta(inp):\n",
    "      return tensor_array_ops.TensorArray(\n",
    "          dtype=inp.dtype, size=array_ops.shape(inp)[0],\n",
    "          element_shape=inp.get_shape()[1:]).unstack(inp)\n",
    "\n",
    "    self._input_tas = nest.map_structure(_unstack_ta, inputs)\n",
    "    sequence_length = ops.convert_to_tensor(\n",
    "        sequence_length, name=\"sequence_length\")\n",
    "    if sequence_length.get_shape().ndims != 1:\n",
    "      raise ValueError(\n",
    "          \"Expected sequence_length to be a vector, but received shape: %s\" %\n",
    "          sequence_length.get_shape())\n",
    "    self._sequence_length = sequence_length\n",
    "    self._zero_inputs = nest.map_structure(\n",
    "        lambda inp: array_ops.zeros_like(inp[0, :]), inputs)\n",
    "    self._batch_size = array_ops.size(sequence_length)\n",
    "\n",
    "  @property\n",
    "  def batch_size(self):\n",
    "    return self._batch_size\n",
    "\n",
    "  def initialize(self):\n",
    "    finished = math_ops.equal(0, self._sequence_length)\n",
    "    all_finished = math_ops.reduce_all(finished)\n",
    "    next_inputs = control_flow_ops.cond(\n",
    "        all_finished, lambda: self._zero_inputs,\n",
    "        lambda: nest.map_structure(lambda inp: inp.read(0), self._input_tas))\n",
    "    return (finished, next_inputs)\n",
    "\n",
    "  def sample(self, time, **unused_kwargs):\n",
    "    next_time = time + 1\n",
    "    finished = (next_time >= self._sequence_length)\n",
    "    all_finished = math_ops.reduce_all(finished)\n",
    "    sample_id = array_ops.tile([constant_op.constant(-1)], [self._batch_size])\n",
    "    next_inputs = control_flow_ops.cond(\n",
    "        all_finished, lambda: self._zero_inputs,\n",
    "        lambda: nest.map_structure(lambda inp: inp.read(next_time), self._input_tas))\n",
    "    return (sample_id, finished, next_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = core_rnn_cell.LSTMCell(cell_depth)\n",
    "sampler = BasicTrainingSampler(\n",
    "    inputs, sequence_length, time_major=time_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BasicTrainingSampler at 0x4315810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequence_length:0' shape=(5,) dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler._sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13792519,  1.66770911,  2.19124269, -0.51016611,  0.99686748,\n",
       "         1.76268172,  1.88533998],\n",
       "       [ 1.31990552,  0.58950371, -1.52749979,  0.41269293,  0.40469393,\n",
       "         0.417514  ,  0.84630972],\n",
       "       [ 0.29173258, -1.76017773, -0.62109584, -0.66316473,  0.41828188,\n",
       "         0.38076872,  0.34394884],\n",
       "       [-0.78217489,  2.46541548, -0.86606914,  1.17914689, -0.08871825,\n",
       "        -0.89538765,  1.38839793],\n",
       "       [-2.44864416,  0.95273793,  0.16966906, -1.02566195,  0.5478496 ,\n",
       "        -0.36753356,  1.13364804]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler._input_tas.read(7).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 7], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops.shape(inputs).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler._zero_inputs.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.batch_size.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finished = math_ops.equal(0, sampler._sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_finished = math_ops.reduce_all(finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_finished.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_id = array_ops.tile([constant_op.constant(-1)], [sampler._batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_decoder = BasicSamplingDecoder(\n",
    "    cell=cell,\n",
    "    sampler=sampler,\n",
    "    initial_state=cell.zero_state(\n",
    "        dtype=dtypes.float32, batch_size=batch_size))\n",
    "\n",
    "final_outputs, final_state = dynamic_decode_rnn(\n",
    "    my_decoder, output_time_major=time_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SamplingDecoderOutput(rnn_output=<tf.Tensor 'TensorArrayStack/TensorArrayGatherV3:0' shape=(?, 5, 10) dtype=float32>, sample_id=<tf.Tensor 'TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, 5) dtype=int32>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_2:0' shape=(5, 10) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs.rnn_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'while/Exit_3:0' shape=(5, 10) dtype=float32>, h=<tf.Tensor 'while/Exit_4:0' shape=(5, 10) dtype=float32>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'while/Exit_3:0' shape=(5, 10) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
