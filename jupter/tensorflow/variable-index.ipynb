{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None])  # 1-D tensor\n",
    "i = tf.placeholder(tf.int32, shape=[1])\n",
    "\n",
    "#---work\n",
    "j = tf.constant(3)\n",
    "y = tf.slice(x, [j], [-1])\n",
    "\n",
    "#--work\n",
    "#y = tf.slice(x, i, [1])\n",
    "\n",
    "#---not work  try use gather, slice...\n",
    "#y = x[i:]\n",
    "#y = x[j:]\n",
    "\n",
    "#--work\n",
    "#y = x[3:]\n",
    "\n",
    "y = tf.gather_nd(x, [i,i])\n",
    "\n",
    "k = tf.constant(1)\n",
    "y = tf.gather_nd(x, [[k]])\n",
    "\n",
    "y = tf.gather(x, [3])\n",
    "\n",
    "#initialize\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#run\n",
    "result = sess.run(y, feed_dict={x: [1, 2, 3, 4, 5], i: [1]})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help(tf.gather_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function gather_nd in module tensorflow.python.ops.gen_array_ops:\n",
      "\n",
      "gather_nd(params, indices, name=None)\n",
      "    Gather values from `params` according to `indices`.\n",
      "    \n",
      "    `indices` must be integer tensor, containing indices into `params`.\n",
      "    It must be shape `[d_0, ..., d_N, R]` where `R` is the rank of `params`.\n",
      "    The innermost dimension of `indices` (with length `R`) corresponds to the\n",
      "    indices of `params`.\n",
      "    \n",
      "    Produces an output tensor with shape `[d_0, ..., d_{n-1}]` where:\n",
      "    \n",
      "        output[i, j, k, ...] = params[indices[i, j, k, ..., :]]\n",
      "    \n",
      "    e.g. for `indices` a matrix:\n",
      "    \n",
      "        output[i] = params[indices[i, :]]\n",
      "    \n",
      "    Args:\n",
      "      params: A `Tensor`. R-D.  The tensor from which to gather values.\n",
      "      indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "        (N+1)-D.  Index tensor having shape `[d_0, ..., d_N, R]`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `params`.\n",
      "      N-D.  Values from `params` gathered from indices given by `indices`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.gather_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sequence_loss_by_example in module tensorflow.python.ops.seq2seq:\n",
      "\n",
      "sequence_loss_by_example(logits, targets, weights, average_across_timesteps=True, softmax_loss_function=None, name=None)\n",
      "    Weighted cross-entropy loss for a sequence of logits (per example).\n",
      "    \n",
      "    Args:\n",
      "      logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].\n",
      "      targets: List of 1D batch-sized int32 Tensors of the same length as logits.\n",
      "      weights: List of 1D batch-sized float-Tensors of the same length as logits.\n",
      "      average_across_timesteps: If set, divide the returned cost by the total\n",
      "        label weight.\n",
      "      softmax_loss_function: Function (inputs-batch, labels-batch) -> loss-batch\n",
      "        to be used instead of the standard softmax (the default if this is None).\n",
      "      name: Optional name for this operation, default: \"sequence_loss_by_example\".\n",
      "    \n",
      "    Returns:\n",
      "      1D batch-sized float Tensor: The log-perplexity for each sequence.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If len(logits) is different from len(targets) or len(weights).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "help(tf.nn.seq2seq.sequence_loss_by_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
