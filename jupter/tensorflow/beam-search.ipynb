{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n",
      "<unknown>\n",
      "<unknown>\n",
      "predicted beam_symbols vs. expected beam_symbols\n",
      "([4, 2, 0], [4, 2, 0])\n",
      "([0, 0, 3], [0, 0, 3])\n",
      "([1, 4, 1], [1, 4, 1])\n",
      "\n",
      "predicted beam_path vs. expected beam_path\n",
      "([0, 0, 0], [0, 0, 0])\n",
      "([1, 0, 0], [1, 0, 0])\n",
      "([1, 2, 0], [1, 2, 0])\n",
      "\n",
      "log beam probs\n",
      "[[-0.6931622 ]\n",
      " [-1.09862733]\n",
      " [-1.79177451]]\n",
      "[[-1.098809  ]\n",
      " [-2.17854738]\n",
      " [-2.26555896]]\n",
      "[[-2.17872906]\n",
      " [-2.26574039]\n",
      " [-2.63273931]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    beam_size = 3 # Number of hypotheses in beam.\n",
    "    num_symbols = 5 # Output vocabulary size.\n",
    "    embedding_size = 10\n",
    "    num_steps = 3\n",
    "    embedding = tf.zeros([num_symbols, embedding_size])\n",
    "    output_projection = None\n",
    "\n",
    "    # log_beam_probs: list of [beam_size, 1] Tensors\n",
    "    #  Ordered log probabilities of the `beam_size` best hypotheses\n",
    "    #  found in each beam step (highest probability first).\n",
    "    # beam_symbols: list of [beam_size] Tensors \n",
    "    #  The ordered `beam_size` words / symbols extracted by the beam\n",
    "    #  step, which will be appended to their corresponding hypotheses\n",
    "    #  (corresponding hypotheses found in `beam_path`).\n",
    "    # beam_path: list of [beam_size] Tensor\n",
    "    #  The ordered `beam_size` parent indices. Their values range\n",
    "    #  from [0, `beam_size`), and they denote which previous\n",
    "    #  hypothesis each word should be appended to.\n",
    "    log_beam_probs, beam_symbols, beam_path  = [], [], []\n",
    "    def beam_search(prev, i):\n",
    "        if output_projection is not None:\n",
    "            prev = tf.nn.xw_plus_b(\n",
    "                prev, output_projection[0], output_projection[1])\n",
    "\n",
    "        # Compute \n",
    "        #  log P(next_word, hypothesis) = \n",
    "        #  log P(next_word | hypothesis)*P(hypothesis) =\n",
    "        #  log P(next_word | hypothesis) + log P(hypothesis)\n",
    "        # for each hypothesis separately, then join them together \n",
    "        # on the same tensor dimension to form the example's \n",
    "        # beam probability distribution:\n",
    "        # [P(word1, hypothesis1), P(word2, hypothesis1), ...,\n",
    "        #  P(word1, hypothesis2), P(word2, hypothesis2), ...]\n",
    "\n",
    "        # If TF had a log_sum_exp operator, then it would be \n",
    "        # more numerically stable to use: \n",
    "        #   probs = prev - tf.log_sum_exp(prev, reduction_dims=[1])\n",
    "        probs = tf.log(tf.nn.softmax(prev))\n",
    "        # i == 1 corresponds to the input being \"<GO>\", with\n",
    "        # uniform prior probability and only the empty hypothesis\n",
    "        # (each row is a separate example).\n",
    "        if i > 1:\n",
    "            probs = tf.reshape(probs + log_beam_probs[-1], \n",
    "                               [-1, beam_size * num_symbols])\n",
    "\n",
    "        # Get the top `beam_size` candidates and reshape them such\n",
    "        # that the number of rows = batch_size * beam_size, which\n",
    "        # allows us to process each hypothesis independently.\n",
    "        best_probs, indices = tf.nn.top_k(probs, beam_size)\n",
    "        indices = tf.stop_gradient(tf.squeeze(tf.reshape(indices, [-1, 1])))\n",
    "        best_probs = tf.stop_gradient(tf.reshape(best_probs, [-1, 1]))\n",
    "\n",
    "        symbols = indices % num_symbols # Which word in vocabulary.\n",
    "        print(symbols.get_shape())\n",
    "        beam_parent = indices // num_symbols # Which hypothesis it came from.\n",
    "\n",
    "        beam_symbols.append(symbols)\n",
    "        beam_path.append(beam_parent)\n",
    "        log_beam_probs.append(best_probs)\n",
    "        return tf.nn.embedding_lookup(embedding, symbols)\n",
    "\n",
    "    # Setting up graph.\n",
    "    inputs = [tf.placeholder(tf.float32, shape=[None, num_symbols])\n",
    "              for i in range(num_steps)]\n",
    "    for i in range(num_steps):\n",
    "        beam_search(inputs[i], i + 1)\n",
    "\n",
    "    # Running the graph.\n",
    "    input_vals = [0, 0, 0]\n",
    "    l = np.log\n",
    "    eps = -10 # exp(-10) ~= 0\n",
    "\n",
    "    # These values mimic the distribution of vocabulary words\n",
    "    # from each hypothesis independently (in log scale since\n",
    "    # they will be put through exp() in softmax).\n",
    "    input_vals[0] = np.array([[0, eps, l(2), eps, l(3)]])\n",
    "    # Step 1 beam hypotheses =\n",
    "    # (1) Path: [4], prob = log(1 / 2)\n",
    "    # (2) Path: [2], prob = log(1 / 3)\n",
    "    # (3) Path: [0], prob = log(1 / 6)\n",
    "\n",
    "    input_vals[1] = np.array([[l(1.2), 0, 0, l(1.1), 0], # Path [4] \n",
    "                              [0,   eps, eps, eps, eps], # Path [2]\n",
    "                              [0,  0,   0,   0,   0]])   # Path [0]\n",
    "    # Step 2 beam hypotheses =\n",
    "    # (1) Path: [2, 0], prob = log(1 / 3) + log(1)\n",
    "    # (2) Path: [4, 0], prob = log(1 / 2) + log(1.2 / 5.3)\n",
    "    # (3) Path: [4, 3], prob = log(1 / 2) + log(1.1 / 5.3)\n",
    "\n",
    "    input_vals[2] = np.array([[0,  l(1.1), 0,   0,   0], # Path [2, 0]\n",
    "                              [eps, 0,   eps, eps, eps], # Path [4, 0]\n",
    "                              [eps, eps, eps, eps, 0]])  # Path [4, 3]\n",
    "    # Step 3 beam hypotheses =\n",
    "    # (1) Path: [4, 0, 1], prob = log(1 / 2) + log(1.2 / 5.3) + log(1)\n",
    "    # (2) Path: [4, 3, 4], prob = log(1 / 2) + log(1.1 / 5.3) + log(1)\n",
    "    # (3) Path: [2, 0, 1], prob = log(1 / 3) + log(1) + log(1.1 / 5.1)\n",
    "\n",
    "    input_feed = {inputs[i]: input_vals[i][:beam_size, :] \n",
    "                  for i in xrange(num_steps)} \n",
    "    output_feed = beam_symbols + beam_path + log_beam_probs\n",
    "    session = tf.InteractiveSession()\n",
    "    outputs = session.run(output_feed, feed_dict=input_feed)\n",
    "\n",
    "    expected_beam_symbols = [[4, 2, 0],\n",
    "                             [0, 0, 3],\n",
    "                             [1, 4, 1]]\n",
    "    expected_beam_path = [[0, 0, 0],\n",
    "                          [1, 0, 0],\n",
    "                          [1, 2, 0]]\n",
    "\n",
    "    print(\"predicted beam_symbols vs. expected beam_symbols\")\n",
    "    for ind, predicted in enumerate(outputs[:num_steps]):\n",
    "        print(list(predicted), expected_beam_symbols[ind])\n",
    "    print(\"\\npredicted beam_path vs. expected beam_path\")\n",
    "    for ind, predicted in enumerate(outputs[num_steps:num_steps * 2]):\n",
    "        print(list(predicted), expected_beam_path[ind])\n",
    "    print(\"\\nlog beam probs\")\n",
    "    for log_probs in outputs[2 * num_steps:]:\n",
    "        print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.top_k??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x5882210>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant([[1.0, 3.0, 2.0, 4.0],[1.8, 1.1, 1.0, 0.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u,v = tf.nn.top_k(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.        ,  3.        ],\n",
       "       [ 1.79999995,  1.10000002]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-916b92179fec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'pinfo2 tf.nn.seq2seq.rnn_decoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "tf.nn.seq2seq.rnn_decoder??\n",
    "res = tf.expand_dims(tensor, 1)\n",
    "res = tf.tile(res, [1, self.beam_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[2.0],[3.0],[4.0]])\n",
    "res = tf.expand_dims(x, 1)\n",
    "res.eval()\n",
    "res.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.],\n",
       "        [ 2.],\n",
       "        [ 2.]],\n",
       "\n",
       "       [[ 3.],\n",
       "        [ 3.],\n",
       "        [ 3.]],\n",
       "\n",
       "       [[ 4.],\n",
       "        [ 4.],\n",
       "        [ 4.]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = tf.tile(res, [1, 3, 1])\n",
    "res.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def tile_along_beam(tensor, beam_size=5):\n",
    "        \"\"\"\n",
    "        Helps tile tensors for each beam.\n",
    "        \n",
    "        Args:\n",
    "          tensor: a 2-D tensor, [batch_size x T]\n",
    "        Return:\n",
    "          An [batch_size*beam_size x T] tensor, where each row of the input\n",
    "          tensor is copied beam_size times in a row in the output\n",
    "        \"\"\"\n",
    "        res = tf.expand_dims(tensor, 1)\n",
    "        res = tf.tile(res, [1, beam_size, 1])\n",
    "        res = tf.reshape(res, [-1, tf.shape(tensor)[1]])\n",
    "        try:\n",
    "            new_first_dim = tensor.get_shape()[0] * self.beam_size\n",
    "        except:\n",
    "            new_first_dim = None\n",
    "        res.set_shape((new_first_dim, tensor.get_shape()[1]))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant([[1.3, 2.4, 1.6], [3.2, 0.2, 1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_along_beam(x).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def tile_along_beam2(tensor, beam_size=5):\n",
    "        \"\"\"\n",
    "        Helps tile tensors for each beam.\n",
    "        \n",
    "        Args:\n",
    "          tensor: a 2-D tensor, [batch_size x T]\n",
    "        Return:\n",
    "          An [batch_size*beam_size x T] tensor, where each row of the input\n",
    "          tensor is copied beam_size times in a row in the output\n",
    "        \"\"\"\n",
    "        res = tf.tile(tensor, [1, beam_size])\n",
    "        #res = tf.reshape(res, [-1, tf.shape(tensor)[1]])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.29999995,  2.4000001 ,  1.60000002,  1.29999995,  2.4000001 ,\n",
       "         1.60000002,  1.29999995,  2.4000001 ,  1.60000002,  1.29999995,\n",
       "         2.4000001 ,  1.60000002,  1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ,  3.20000005,  0.2       ,\n",
       "         1.5       ,  3.20000005,  0.2       ,  1.5       ,  3.20000005,\n",
       "         0.2       ,  1.5       ,  3.20000005,  0.2       ,  1.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_along_beam2(x).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tile_along_beam2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got -1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-36c11535fa13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   2446\u001b[0m   \"\"\"\n\u001b[0;32m   2447\u001b[0m   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\n\u001b[1;32m-> 2448\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m   2449\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    491\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m               raise TypeError(\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got -1"
     ]
    }
   ],
   "source": [
    "tf.reshape(y, [-1, x.get_shape()[1]]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(y, [-1, tf.shape(x)[1]]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ],\n",
       "       [ 1.29999995,  2.4000001 ,  1.60000002],\n",
       "       [ 3.20000005,  0.2       ,  1.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.tile(x, [5, 1]), [-1, tf.shape(x)[1]]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "        nondone_mask = tf.reshape(\n",
    "            tf.cast(tf.equal(tf.range(4), 3), tf.float32) * -1e18,\n",
    "            [1, 1, 4]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -0.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "          -9.99999984e+17]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nondone_mask.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.equal(tf.range(4), 3).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.equal(tf.range(4), 2), tf.float32).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.expand_dims?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nondone_mask.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-734ac99ebe17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tf.reshape(\n\u001b[0;32m      2\u001b[0m           \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m       ).eval()\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3622\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3624\u001b[1;33m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[0;32m   3625\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3626\u001b[0m                        \u001b[1;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
     ]
    }
   ],
   "source": [
    "tf.reshape(\n",
    "          (tf.range(2 * 3) // 3) * 3,\n",
    "          [2, 3]\n",
    "      ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(\n",
    "          (tf.range(3 * 5) // 5) * 5,\n",
    "          [3, 5]\n",
    "      ).eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.select?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
