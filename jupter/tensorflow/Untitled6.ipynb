{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b8a8122841b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function exponential_decay in module tensorflow.python.training.learning_rate_decay:\n",
      "\n",
      "exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None)\n",
      "    Applies exponential decay to the learning rate.\n",
      "    \n",
      "    When training a model, it is often recommended to lower the learning rate as\n",
      "    the training progresses.  This function applies an exponential decay function\n",
      "    to a provided initial learning rate.  It requires a `global_step` value to\n",
      "    compute the decayed learning rate.  You can just pass a TensorFlow variable\n",
      "    that you increment at each training step.\n",
      "    \n",
      "    The function returns the decayed learning rate.  It is computed as:\n",
      "    \n",
      "    ```python\n",
      "    decayed_learning_rate = learning_rate *\n",
      "                            decay_rate ^ (global_step / decay_steps)\n",
      "    ```\n",
      "    \n",
      "    If the argument `staircase` is `True`, then `global_step / decay_steps` is an\n",
      "    integer division and the decayed learning rate follows a staircase function.\n",
      "    \n",
      "    Example: decay every 100000 steps with a base of 0.96:\n",
      "    \n",
      "    ```python\n",
      "    ...\n",
      "    global_step = tf.Variable(0, trainable=False)\n",
      "    starter_learning_rate = 0.1\n",
      "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
      "                                               100000, 0.96, staircase=True)\n",
      "    # Passing global_step to minimize() will increment it at each step.\n",
      "    learning_step = (\n",
      "        tf.GradientDescentOptimizer(learning_rate)\n",
      "        .minimize(...my loss..., global_step=global_step)\n",
      "    )\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      learning_rate: A scalar `float32` or `float64` `Tensor` or a\n",
      "        Python number.  The initial learning rate.\n",
      "      global_step: A scalar `int32` or `int64` `Tensor` or a Python number.\n",
      "        Global step to use for the decay computation.  Must not be negative.\n",
      "      decay_steps: A scalar `int32` or `int64` `Tensor` or a Python number.\n",
      "        Must be positive.  See the decay computation above.\n",
      "      decay_rate: A scalar `float32` or `float64` `Tensor` or a\n",
      "        Python number.  The decay rate.\n",
      "      staircase: Boolean.  It `True` decay the learning rate at discrete intervals\n",
      "      name: String.  Optional name of the operation.  Defaults to \n",
      "        'ExponentialDecay'\n",
      "    \n",
      "    Returns:\n",
      "      A scalar `Tensor` of the same type as `learning_rate`.  The decayed\n",
      "      learning rate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.train.exponential_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function shuffle_batch in module tensorflow.python.training.input:\n",
      "\n",
      "shuffle_batch(tensors, batch_size, capacity, min_after_dequeue, num_threads=1, seed=None, enqueue_many=False, shapes=None, shared_name=None, name=None)\n",
      "    Creates batches by randomly shuffling tensors.\n",
      "    \n",
      "    This function adds the following to the current `Graph`:\n",
      "    \n",
      "    * A shuffling queue into which tensors from `tensors` are enqueued.\n",
      "    * A `dequeue_many` operation to create batches from the queue.\n",
      "    * A `QueueRunner` to `QUEUE_RUNNER` collection, to enqueue the tensors\n",
      "      from `tensors`.\n",
      "    \n",
      "    If `enqueue_many` is `False`, `tensors` is assumed to represent a\n",
      "    single example.  An input tensor with shape `[x, y, z]` will be output\n",
      "    as a tensor with shape `[batch_size, x, y, z]`.\n",
      "    \n",
      "    If `enqueue_many` is `True`, `tensors` is assumed to represent a\n",
      "    batch of examples, where the first dimension is indexed by example,\n",
      "    and all members of `tensors` should have the same size in the\n",
      "    first dimension.  If an input tensor has shape `[*, x, y, z]`, the\n",
      "    output will have shape `[batch_size, x, y, z]`.\n",
      "    \n",
      "    The `capacity` argument controls the how long the prefetching is allowed to\n",
      "    grow the queues.\n",
      "    \n",
      "    The returned operation is a dequeue operation and will throw\n",
      "    `tf.errors.OutOfRangeError` if the input queue is exhausted. If this\n",
      "    operation is feeding another input queue, its queue runner will catch\n",
      "    this exception, however, if this operation is used in your main thread\n",
      "    you are responsible for catching this yourself.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # Creates batches of 32 images and 32 labels.\n",
      "    image_batch, label_batch = tf.train.shuffle_batch(\n",
      "          [single_image, single_label],\n",
      "          batch_size=32,\n",
      "          num_threads=4,\n",
      "          capacity=50000,\n",
      "          min_after_dequeue=10000)\n",
      "    ```\n",
      "    \n",
      "    *N.B.:* You must ensure that either (i) the `shapes` argument is\n",
      "    passed, or (ii) all of the tensors in `tensors` must have\n",
      "    fully-defined shapes. `ValueError` will be raised if neither of\n",
      "    these conditions holds.\n",
      "    \n",
      "    Args:\n",
      "      tensors: The list or dictionary of tensors to enqueue.\n",
      "      batch_size: The new batch size pulled from the queue.\n",
      "      capacity: An integer. The maximum number of elements in the queue.\n",
      "      min_after_dequeue: Minimum number elements in the queue after a\n",
      "        dequeue, used to ensure a level of mixing of elements.\n",
      "      num_threads: The number of threads enqueuing `tensor_list`.\n",
      "      seed: Seed for the random shuffling within the queue.\n",
      "      enqueue_many: Whether each tensor in `tensor_list` is a single example.\n",
      "      shapes: (Optional) The shapes for each example.  Defaults to the\n",
      "        inferred shapes for `tensor_list`.\n",
      "      shared_name: (Optional) If set, this queue will be shared under the given\n",
      "        name across multiple sessions.\n",
      "      name: (Optional) A name for the operations.\n",
      "    \n",
      "    Returns:\n",
      "      A list or dictionary of tensors with the types as `tensors`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If the `shapes` are not specified, and cannot be\n",
      "        inferred from the elements of `tensors`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.train.shuffle_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function full in module numpy.core.numeric:\n",
      "\n",
      "full(shape, fill_value, dtype=None, order='C')\n",
      "    Return a new array of given shape and type, filled with `fill_value`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    shape : int or sequence of ints\n",
      "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
      "    fill_value : scalar\n",
      "        Fill value.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array, e.g., `np.int8`.  Default\n",
      "        is `float`, but will change to `np.array(fill_value).dtype` in a\n",
      "        future release.\n",
      "    order : {'C', 'F'}, optional\n",
      "        Whether to store multidimensional data in C- or Fortran-contiguous\n",
      "        (row- or column-wise) order in memory.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of `fill_value` with the given shape, dtype, and order.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    full_like : Fill an array with shape and type of input.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "    ones : Return a new array setting values to one.\n",
      "    empty : Return a new uninitialized array.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.full((2, 2), np.inf)\n",
      "    array([[ inf,  inf],\n",
      "           [ inf,  inf]])\n",
      "    >>> np.full((2, 2), 10, dtype=np.int)\n",
      "    array([[10, 10],\n",
      "           [10, 10]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function hstack in module numpy.core.shape_base:\n",
      "\n",
      "hstack(tup)\n",
      "    Stack arrays in sequence horizontally (column wise).\n",
      "    \n",
      "    Take a sequence of arrays and stack them horizontally to make\n",
      "    a single array. Rebuild arrays divided by `hsplit`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        All arrays must have the same shape along all but the second axis.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    hsplit : Split array along second axis.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Equivalent to ``np.concatenate(tup, axis=1)``\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array((1,2,3))\n",
      "    >>> b = np.array((2,3,4))\n",
      "    >>> np.hstack((a,b))\n",
      "    array([1, 2, 3, 2, 3, 4])\n",
      "    >>> a = np.array([[1],[2],[3]])\n",
      "    >>> b = np.array([[2],[3],[4]])\n",
      "    >>> np.hstack((a,b))\n",
      "    array([[1, 2],\n",
      "           [2, 3],\n",
      "           [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.hstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[1 2 3 4]\n",
      "[4]\n",
      "[0 0]\n",
      "[[1 2 3]\n",
      " [4 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x6b67d50>> ignored\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "print a.eval()\n",
    "\n",
    "# Reshape `a` as a vector. -1 means \"set this dimension automatically\".\n",
    "a_as_vector = tf.reshape(a, [-1])\n",
    "print a_as_vector.eval()\n",
    "\n",
    "# Create another vector containing zeroes to pad `a` to (2 * 3) elements.\n",
    "zero_padding = tf.zeros([2 * 3] - tf.shape(a_as_vector), dtype=a.dtype)\n",
    "\n",
    "print tf.shape(a_as_vector).eval()\n",
    "print zero_padding.eval()\n",
    "\n",
    "# Concatenate `a_as_vector` with the padding.\n",
    "a_padded = tf.concat(0, [a_as_vector, zero_padding])\n",
    "\n",
    "# Reshape the padded vector to the desired shape.\n",
    "result = tf.reshape(a_padded, [2, 3])\n",
    "\n",
    "print result.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[2 0]\n",
      "[[2 0]\n",
      " [6 0]]\n",
      "[[2 4]\n",
      " [0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x324df50>> ignored\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[0,2], [1, 0]])\n",
    "print a.eval()\n",
    "\n",
    "c = b[:,1]\n",
    "print c.eval()\n",
    "\n",
    "d = a * c\n",
    "print d.eval()\n",
    "\n",
    "d = a * tf.expand_dims(b[:,1], 1)\n",
    "print d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function softmax_cross_entropy_with_logits in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "softmax_cross_entropy_with_logits(logits, labels, name=None)\n",
      "    Computes softmax cross entropy between `logits` and `labels`.\n",
      "    \n",
      "    Measures the probability error in discrete classification tasks in which the\n",
      "    classes are mutually exclusive (each entry is in exactly one class).  For\n",
      "    example, each CIFAR-10 image is labeled with one and only one label: an image\n",
      "    can be a dog or a truck, but not both.\n",
      "    \n",
      "    **NOTE:**  While the classes are mutually exclusive, their probabilities\n",
      "    need not be.  All that is required is that each row of `labels` is\n",
      "    a valid probability distribution.  If they are not, the computation of the\n",
      "    gradient will be incorrect.\n",
      "    \n",
      "    If using exclusive `labels` (wherein one and only\n",
      "    one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`.\n",
      "    \n",
      "    **WARNING:** This op expects unscaled logits, since it performs a `softmax`\n",
      "    on `logits` internally for efficiency.  Do not call this op with the\n",
      "    output of `softmax`, as it will produce incorrect results.\n",
      "    \n",
      "    `logits` and `labels` must have the same shape `[batch_size, num_classes]`\n",
      "    and the same dtype (either `float32` or `float64`).\n",
      "    \n",
      "    Args:\n",
      "      logits: Unscaled log probabilities.\n",
      "      labels: Each row `labels[i]` must be a valid probability distribution.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A 1-D `Tensor` of length `batch_size` of the same type as `logits` with the\n",
      "      softmax cross entropy loss.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.softmax_cross_entropy_with_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sparse_softmax_cross_entropy_with_logits in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "sparse_softmax_cross_entropy_with_logits(logits, labels, name=None)\n",
      "    Computes sparse softmax cross entropy between `logits` and `labels`.\n",
      "    \n",
      "    Measures the probability error in discrete classification tasks in which the\n",
      "    classes are mutually exclusive (each entry is in exactly one class).  For\n",
      "    example, each CIFAR-10 image is labeled with one and only one label: an image\n",
      "    can be a dog or a truck, but not both.\n",
      "    \n",
      "    **NOTE:**  For this operation, the probability of a given label is considered\n",
      "    exclusive.  That is, soft classes are not allowed, and the `labels` vector\n",
      "    must provide a single specific index for the true class for each row of\n",
      "    `logits` (each minibatch entry).  For soft softmax classification with\n",
      "    a probability distribution for each entry, see\n",
      "    `softmax_cross_entropy_with_logits`.\n",
      "    \n",
      "    **WARNING:** This op expects unscaled logits, since it performs a softmax\n",
      "    on `logits` internally for efficiency.  Do not call this op with the\n",
      "    output of `softmax`, as it will produce incorrect results.\n",
      "    \n",
      "    A common use case is to have logits of shape `[batch_size, num_classes]` and\n",
      "    labels of shape `[batch_size]`. But higher dimensions are supported.\n",
      "    \n",
      "    Args:\n",
      "      logits: Unscaled log probabilities of rank `r` and shape\n",
      "        `[d_0, d_1, ..., d_{r-2}, num_classes]` and dtype `float32` or `float64`.\n",
      "      labels: `Tensor` of shape `[d_0, d_1, ..., d_{r-2}]` and dtype `int32` or\n",
      "        `int64`. Each entry in `labels` must be an index in `[0, num_classes)`.\n",
      "        Other values will result in a loss of 0, but incorrect gradient\n",
      "        computations.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` of the same shape as `labels` and of the same type as `logits`\n",
      "      with the softmax cross entropy loss.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If logits are scalars (need to have rank >= 1) or if the rank\n",
      "        of the labels is not equal to the rank of the labels minus one.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.sparse_softmax_cross_entropy_with_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'gather'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-924e81a89196>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'gather'"
     ]
    }
   ],
   "source": [
    "a.gather(0).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(a, 0).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = tf.slice(a, [0, 0], [1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (1, 2) must have rank 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3513dbb78d76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36mfill\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m   \"\"\"\n\u001b[1;32m--> 808\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fill\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                            op_def=op_def)\n\u001b[0m\u001b[0;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2298\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2299\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2300\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2301\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2302\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[0;32m   1703\u001b[0m                          % op.type)\n\u001b[1;32m-> 1704\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1705\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36m_FillShape\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1883\u001b[0m   \"\"\"\n\u001b[0;32m   1884\u001b[0m   \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_has_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1885\u001b[1;33m   \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_has_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1886\u001b[0m   \u001b[0mfill_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1887\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mfill_dims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfill_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_has_rank\u001b[1;34m(self, rank)\u001b[0m\n\u001b[0;32m    619\u001b[0m     \"\"\"\n\u001b[0;32m    620\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape (1, 2) must have rank 0"
     ]
    }
   ],
   "source": [
    "tf.fill([3, 2], b).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 2],\n",
       "       [1, 2]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(0, [b] * 3).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "pad(tensor, paddings, mode='CONSTANT', name=None)\n",
      "    Pads a tensor.\n",
      "    \n",
      "    This operation pads a `tensor` according to the `paddings` you specify.\n",
      "    `paddings` is an integer tensor with shape `[n, 2]`, where n is the rank of\n",
      "    `tensor`. For each dimension D of `input`, `paddings[D, 0]` indicates how\n",
      "    many values to add before the contents of `tensor` in that dimension, and\n",
      "    `paddings[D, 1]` indicates how many values to add after the contents of\n",
      "    `tensor` in that dimension. If `mode` is \"REFLECT\" then both `paddings[D, 0]`\n",
      "    and `paddings[D, 1]` must be no greater than `tensor.dim_size(D) - 1`. If\n",
      "    `mode` is \"SYMMETRIC\" then both `paddings[D, 0]` and `paddings[D, 1]` must be\n",
      "    no greater than `tensor.dim_size(D)`.\n",
      "    \n",
      "    The padded size of each dimension D of the output is:\n",
      "    \n",
      "    `paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]`\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # 't' is [[1, 2, 3], [4, 5, 6]].\n",
      "    # 'paddings' is [[1, 1,], [2, 2]].\n",
      "    # rank of 't' is 2.\n",
      "    pad(t, paddings, \"CONSTANT\") ==> [[0, 0, 0, 0, 0, 0, 0],\n",
      "                                      [0, 0, 1, 2, 3, 0, 0],\n",
      "                                      [0, 0, 4, 5, 6, 0, 0],\n",
      "                                      [0, 0, 0, 0, 0, 0, 0]]\n",
      "    \n",
      "    pad(t, paddings, \"REFLECT\") ==> [[6, 5, 4, 5, 6, 5, 4],\n",
      "                                     [3, 2, 1, 2, 3, 2, 1],\n",
      "                                     [6, 5, 4, 5, 6, 5, 4],\n",
      "                                     [3, 2, 1, 2, 3, 2, 1]]\n",
      "    \n",
      "    pad(t, paddings, \"SYMMETRIC\") ==> [[2, 1, 1, 2, 3, 3, 2],\n",
      "                                       [2, 1, 1, 2, 3, 3, 2],\n",
      "                                       [5, 4, 4, 5, 6, 6, 5],\n",
      "                                       [5, 4, 4, 5, 6, 6, 5]]\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      tensor: A `Tensor`.\n",
      "      paddings: A `Tensor` of type `int32`.\n",
      "      mode: One of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\".\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: When mode is not one of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named nn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5e8ed7a88eaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named nn"
     ]
    }
   ],
   "source": [
    "import tensorflow.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0), 16384)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.nn.absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named nn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5e8ed7a88eaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named nn"
     ]
    }
   ],
   "source": [
    "import tensorflow.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow.python.ops.nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dae89ba154e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'nn'"
     ]
    }
   ],
   "source": [
    "nn = tensorflow.python.ops.nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-baf416708afb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "help(tf.random_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function random_uniform in module tensorflow.python.ops.random_ops:\n",
      "\n",
      "random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)\n",
      "    Outputs random values from a uniform distribution.\n",
      "    \n",
      "    The generated values follow a uniform distribution in the range\n",
      "    `[minval, maxval)`. The lower bound `minval` is included in the range, while\n",
      "    the upper bound `maxval` is excluded.\n",
      "    \n",
      "    For floats, the default range is `[0, 1)`.  For ints, at least `maxval` must\n",
      "    be specified explicitly.\n",
      "    \n",
      "    In the integer case, the random integers are slightly biased unless\n",
      "    `maxval - minval` is an exact power of two.  The bias is small for values of\n",
      "    `maxval - minval` significantly smaller than the range of the output (either\n",
      "    `2**32` or `2**64`).\n",
      "    \n",
      "    Args:\n",
      "      shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "      minval: A 0-D Tensor or Python value of type `dtype`. The lower bound on the\n",
      "        range of random values to generate.  Defaults to 0.\n",
      "      maxval: A 0-D Tensor or Python value of type `dtype`. The upper bound on\n",
      "        the range of random values to generate.  Defaults to 1 if `dtype` is\n",
      "        floating point.\n",
      "      dtype: The type of the output: `float32`, `float64`, `int32`, or `int64`.\n",
      "      seed: A Python integer. Used to create a random seed for the distribution.\n",
      "        See\n",
      "        [`set_random_seed`](../../api_docs/python/constant_op.md#set_random_seed)\n",
      "        for behavior.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A tensor of the specified shape filled with random uniform values.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `dtype` is integral and `maxval` is not specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.random_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function random_uniform_initializer in module tensorflow.python.ops.init_ops:\n",
      "\n",
      "random_uniform_initializer(minval=0.0, maxval=1.0, seed=None, dtype=tf.float32)\n",
      "    Returns an initializer that generates tensors with a uniform distribution.\n",
      "    \n",
      "    Args:\n",
      "      minval: a python scalar or a scalar tensor. lower bound of the range\n",
      "        of random values to generate.\n",
      "      maxval: a python scalar or a scalar tensor. upper bound of the range\n",
      "        of random values to generate.\n",
      "      seed: A Python integer. Used to create random seeds. See\n",
      "        [`set_random_seed`](../../api_docs/python/constant_op.md#set_random_seed)\n",
      "        for behavior.\n",
      "      dtype: The data type. Only floating point types are supported.\n",
      "    \n",
      "    Returns:\n",
      "      An initializer that generates tensors with a uniform distribution.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: if `dtype` is not a floating point type.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.random_uniform_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function shuffle_batch in module tensorflow.python.training.input:\n",
      "\n",
      "shuffle_batch(tensors, batch_size, capacity, min_after_dequeue, num_threads=1, seed=None, enqueue_many=False, shapes=None, allow_smaller_final_batch=False, shared_name=None, name=None)\n",
      "    Creates batches by randomly shuffling tensors.\n",
      "    \n",
      "    This function adds the following to the current `Graph`:\n",
      "    \n",
      "    * A shuffling queue into which tensors from `tensors` are enqueued.\n",
      "    * A `dequeue_many` operation to create batches from the queue.\n",
      "    * A `QueueRunner` to `QUEUE_RUNNER` collection, to enqueue the tensors\n",
      "      from `tensors`.\n",
      "    \n",
      "    If `enqueue_many` is `False`, `tensors` is assumed to represent a\n",
      "    single example.  An input tensor with shape `[x, y, z]` will be output\n",
      "    as a tensor with shape `[batch_size, x, y, z]`.\n",
      "    \n",
      "    If `enqueue_many` is `True`, `tensors` is assumed to represent a\n",
      "    batch of examples, where the first dimension is indexed by example,\n",
      "    and all members of `tensors` should have the same size in the\n",
      "    first dimension.  If an input tensor has shape `[*, x, y, z]`, the\n",
      "    output will have shape `[batch_size, x, y, z]`.\n",
      "    \n",
      "    The `capacity` argument controls the how long the prefetching is allowed to\n",
      "    grow the queues.\n",
      "    \n",
      "    The returned operation is a dequeue operation and will throw\n",
      "    `tf.errors.OutOfRangeError` if the input queue is exhausted. If this\n",
      "    operation is feeding another input queue, its queue runner will catch\n",
      "    this exception, however, if this operation is used in your main thread\n",
      "    you are responsible for catching this yourself.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # Creates batches of 32 images and 32 labels.\n",
      "    image_batch, label_batch = tf.train.shuffle_batch(\n",
      "          [single_image, single_label],\n",
      "          batch_size=32,\n",
      "          num_threads=4,\n",
      "          capacity=50000,\n",
      "          min_after_dequeue=10000)\n",
      "    ```\n",
      "    \n",
      "    *N.B.:* You must ensure that either (i) the `shapes` argument is\n",
      "    passed, or (ii) all of the tensors in `tensors` must have\n",
      "    fully-defined shapes. `ValueError` will be raised if neither of\n",
      "    these conditions holds.\n",
      "    \n",
      "    If `allow_smaller_final_batch` is `True`, a smaller batch value than\n",
      "    `batch_size` is returned when the queue is closed and there are not enough\n",
      "    elements to fill the batch, otherwise the pending elements are discarded.\n",
      "    In addition, all output tensors' static shapes, as accessed via the\n",
      "    `get_shape` method will have a first `Dimension` value of `None`, and\n",
      "    operations that depend on fixed batch_size would fail.\n",
      "    \n",
      "    Args:\n",
      "      tensors: The list or dictionary of tensors to enqueue.\n",
      "      batch_size: The new batch size pulled from the queue.\n",
      "      capacity: An integer. The maximum number of elements in the queue.\n",
      "      min_after_dequeue: Minimum number elements in the queue after a\n",
      "        dequeue, used to ensure a level of mixing of elements.\n",
      "      num_threads: The number of threads enqueuing `tensor_list`.\n",
      "      seed: Seed for the random shuffling within the queue.\n",
      "      enqueue_many: Whether each tensor in `tensor_list` is a single example.\n",
      "      shapes: (Optional) The shapes for each example.  Defaults to the\n",
      "        inferred shapes for `tensor_list`.\n",
      "      allow_smaller_final_batch: (Optional) Boolean. If `True`, allow the final\n",
      "        batch to be smaller if there are insufficient items left in the queue.\n",
      "      shared_name: (Optional) If set, this queue will be shared under the given\n",
      "        name across multiple sessions.\n",
      "      name: (Optional) A name for the operations.\n",
      "    \n",
      "    Returns:\n",
      "      A list or dictionary of tensors with the types as `tensors`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If the `shapes` are not specified, and cannot be\n",
      "        inferred from the elements of `tensors`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.train.shuffle_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function batch in module tensorflow.python.training.input:\n",
      "\n",
      "batch(tensors, batch_size, num_threads=1, capacity=32, enqueue_many=False, shapes=None, dynamic_pad=False, allow_smaller_final_batch=False, shared_name=None, name=None)\n",
      "    Creates batches of tensors in `tensors`.\n",
      "    \n",
      "    The argument `tensors` can be a list or a dictionary of tensors.\n",
      "    The value returned by the function will be of the same type\n",
      "    as `tensors`.\n",
      "    \n",
      "    This function is implemented using a queue. A `QueueRunner` for the\n",
      "    queue is added to the current `Graph`'s `QUEUE_RUNNER` collection.\n",
      "    \n",
      "    If `enqueue_many` is `False`, `tensors` is assumed to represent a single\n",
      "    example.  An input tensor with shape `[x, y, z]` will be output as a tensor\n",
      "    with shape `[batch_size, x, y, z]`.\n",
      "    \n",
      "    If `enqueue_many` is `True`, `tensors` is assumed to represent a batch of\n",
      "    examples, where the first dimension is indexed by example, and all members of\n",
      "    `tensor_list` should have the same size in the first dimension.  If an input\n",
      "    tensor has shape `[*, x, y, z]`, the output will have shape `[batch_size, x,\n",
      "    y, z]`.  The `capacity` argument controls the how long the prefetching is\n",
      "    allowed to grow the queues.\n",
      "    \n",
      "    The returned operation is a dequeue operation and will throw\n",
      "    `tf.errors.OutOfRangeError` if the input queue is exhausted. If this\n",
      "    operation is feeding another input queue, its queue runner will catch\n",
      "    this exception, however, if this operation is used in your main thread\n",
      "    you are responsible for catching this yourself.\n",
      "    \n",
      "    *N.B.:* If `dynamic_pad` is `False`, you must ensure that either\n",
      "    (i) the `shapes` argument is passed, or (ii) all of the tensors in\n",
      "    `tensors` must have fully-defined shapes. `ValueError` will be\n",
      "    raised if neither of these conditions holds.\n",
      "    \n",
      "    If `dynamic_pad` is `True`, it is sufficient that the *rank* of the\n",
      "    tensors is known, but individual dimensions may have shape `None`.\n",
      "    In this case, for each enqueue the dimensions with value `None`\n",
      "    may have a variable length; upon dequeue, the output tensors will be padded\n",
      "    on the right to the maximum shape of the tensors in the current minibatch.\n",
      "    For numbers, this padding takes value 0.  For strings, this padding is\n",
      "    the empty string.  See `PaddingFIFOQueue` for more info.\n",
      "    \n",
      "    If `allow_smaller_final_batch` is `True`, a smaller batch value than\n",
      "    `batch_size` is returned when the queue is closed and there are not enough\n",
      "    elements to fill the batch, otherwise the pending elements are discarded.\n",
      "    In addition, all output tensors' static shapes, as accessed via the\n",
      "    `get_shape` method will have a first `Dimension` value of `None`, and\n",
      "    operations that depend on fixed batch_size would fail.\n",
      "    \n",
      "    Args:\n",
      "      tensors: The list or dictionary of tensors to enqueue.\n",
      "      batch_size: The new batch size pulled from the queue.\n",
      "      num_threads: The number of threads enqueuing `tensor_list`.\n",
      "      capacity: An integer. The maximum number of elements in the queue.\n",
      "      enqueue_many: Whether each tensor in `tensor_list` is a single example.\n",
      "      shapes: (Optional) The shapes for each example.  Defaults to the\n",
      "        inferred shapes for `tensor_list`.\n",
      "      dynamic_pad: Boolean.  Allow variable dimensions in input shapes.\n",
      "        The given dimensions are padded upon dequeue so that tensors within a\n",
      "        batch have the same shapes.\n",
      "      allow_smaller_final_batch: (Optional) Boolean. If `True`, allow the final\n",
      "        batch to be smaller if there are insufficient items left in the queue.\n",
      "      shared_name: (Optional). If set, this queue will be shared under the given\n",
      "        name across multiple sessions.\n",
      "      name: (Optional) A name for the operations.\n",
      "    \n",
      "    Returns:\n",
      "      A list or dictionary of tensors with the same types as `tensors`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If the `shapes` are not specified, and cannot be\n",
      "        inferred from the elements of `tensors`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.train.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
