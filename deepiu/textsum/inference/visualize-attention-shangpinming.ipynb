{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.2.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('vocab', '/home/gezi/new/temp/shangpinming/tfrecord/seq-basic/vocab.txt', 'vocabulary file')\n",
    "\n",
    "model_dir='/home/gezi/new/temp/shangpinming/model/seq2seq.attention/'\n",
    "\n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "from deepiu.util import text2ids\n",
    "\n",
    "TEXT_MAX_WORDS = 20\n",
    "INPUT_TEXT_MAX_WORDS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _text2ids(text, max_words):\n",
    "  word_ids = text2ids.text2ids(text, \n",
    "                               seg_method='basic', \n",
    "                               feed_single=True, \n",
    "                               allow_all_zero=True, \n",
    "                               pad=False)\n",
    "  #word_ids.append(text2ids.vocab.end_id())\n",
    "  word_ids = word_ids[:max_words]\n",
    "  word_ids = gezi.pad(word_ids, max_words, 0)\n",
    "\n",
    "  return word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libgezi import utf82gbk, gbk2utf8\n",
    "def predict(predictor, input_text):\n",
    "  input_text = utf82gbk(input_text)\n",
    "  word_ids = _text2ids(input_text, INPUT_TEXT_MAX_WORDS)\n",
    "  print('word_ids', word_ids, 'len:', len(word_ids))\n",
    "  print(gbk2utf8(text2ids.ids2text(word_ids)))\n",
    "\n",
    "  timer = gezi.Timer()\n",
    "  init_states = predictor.inference([\n",
    "                                        'beam_search_beam_size',\n",
    "                                        'beam_search_initial_state', \n",
    "                                        'beam_search_initial_ids', \n",
    "                                        'beam_search_initial_logprobs',\n",
    "                                        'beam_search_initial_alignments'\n",
    "                                        ], \n",
    "                                        feed_dict= {\n",
    "                                          tf.get_collection('input_text_feed')[0] : [word_ids]\n",
    "                                        })\n",
    "\n",
    "  step_func = lambda input_feed, state_feed : predictor.inference([\n",
    "                                        'beam_search_state', \n",
    "                                        'beam_search_ids', \n",
    "                                        'beam_search_logprobs',\n",
    "                                        'beam_search_alignments', \n",
    "                                        ], \n",
    "                                        feed_dict= {\n",
    "                                          #TODO...attetion still need input_text feed, see rnn_decoder.py  beam_search_step\n",
    "                                          #but not hurt perfomance much because encoder is fast? Is it possible to avoid this?\n",
    "                                          #anyway if no attention  will not need input_text_feed\n",
    "                                          tf.get_collection('input_text_feed')[0] : [word_ids],\n",
    "                                          tf.get_collection('beam_search_input_feed')[0] : input_feed,\n",
    "                                          tf.get_collection('beam_search_state_feed')[0] : state_feed\n",
    "                                        })\n",
    "\n",
    "  max_words = TEXT_MAX_WORDS\n",
    "  beams = melt.seq2seq.beam_search(init_states, \n",
    "                                   step_func, \n",
    "                                   end_id=text2ids.end_id(), \n",
    "                                   max_words=max_words, \n",
    "                                   length_normalization_factor=0.)\n",
    "\n",
    "  #print(len(beams))\n",
    "  #x_labels = [gbk2utf8(text2ids.vocab.key(x)).encode('utf8') for x in word_ids]\n",
    "  for i, beam in enumerate(beams):\n",
    "    print(gbk2utf8(text2ids.ids2text(word_ids)))\n",
    "    print(i, beam.words, gbk2utf8(text2ids.ids2text(beam.words)), math.exp(beam.logprob), beam.logprob, beam.score, beam.logprobs)\n",
    "    #print(beam.alignments_list)\n",
    "\n",
    "    #plt.matshow(beam.alignments_list)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(beam.alignments_list, interpolation='nearest')\n",
    "    #fig.colorbar(cax)\n",
    "\n",
    "    #ax.set_xticklabels(['']+x_labels)\n",
    "    #ax.set_yticklabels(['']+alpha)\n",
    "\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "\n",
    "  print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gezi/new/temp/shangpinming/tfrecord/seq-basic/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "print(FLAGS.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n",
      "restore from /home/gezi/new/temp/shangpinming/model/seq2seq.attention/model.ckpt-7.2-65000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/gezi/new/temp/shangpinming/model/seq2seq.attention/model.ckpt-7.2-65000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "import graph ok /home/gezi/new/temp/shangpinming/model/seq2seq.attention/model.ckpt-7.2-65000.meta\n",
      "restore ok /home/gezi/new/temp/shangpinming/model/seq2seq.attention/model.ckpt-7.2-65000\n"
     ]
    }
   ],
   "source": [
    "text2ids.init(FLAGS.vocab)\n",
    "predictor = melt.Predictor(model_dir)\n",
    "\n",
    "def inference(text):\n",
    "  predict(predictor, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_ids [411, 21, 2640, 1733, 232, 93, 18, 324, 196, 7, 2035, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] len: 30\n",
      "美国/代购/Vaseline/凡士林/深层/滋润/保湿/修复/护手/霜/护甲\n",
      "美国/代购/Vaseline/凡士林/深层/滋润/保湿/修复/护手/霜/护甲\n",
      "0 [2640, 6, 1733, 3, 1479, 93, 7, 2] Vaseline///凡士林/ /特效/滋润/霜/<EOS> 0.040701924127 -3.20148 -3.20148 [-0.5682382, -0.1519862, -0.092659593, -0.00047731926, -1.502073, -0.52623391, -0.35842815, -0.0013834201]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAACBCAYAAAA45zYjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAADGNJREFUeJzt3X/sXXV5wPH3Y8EijFUrgligLd9SihsgTLPo6JaNuBDM\nGEmFMRUnbjEaN5tV/xn74ci2bCxbFI1JGWj4ETcTQmCOMaoDhiuRqWllVoEibQctKIwKNJYW2j77\n457Su/be2/O53PO9v96v5Ib7Pfc55/N8OBeee875nM+JzESSpBKvGXYCkqTxY/GQJBWzeEiSilk8\nJEnFLB6SpGIWD0lSMYuHJKlY48UjIpZExP0R8UhE/FdEnNF0m6MgIrZExEMRsT4i1kXEJcPOqQkR\ncU1EbI6IfRFxVtvyN0XEv0XExoj474hYPsw8B61Hv/8jIjZV+3xdRKwcZp6DFhFzI+K2iHi4+m6v\niYiZ6rOJ3edd+n1q9dlE7/OuMrPRF3A3cHn1fgXwrabbHIUXsAk4c9h5zEI/zwPeUvX3rLblXwT+\nrHr/duAJYM6w852Fft8L/Maw82uw33OBC9r+/jhwb/X+S5O6z7v0+55p2OfdXo0eeUTEm4BfAL4M\nkJm3Aifvr9gTLqrXRMvMtZn5JIf29VJgdRXzHWAb8CuznF5jevQbJvh0cGbuzsy72hY9ACys3l/C\nhO7zLv1e1Pb3xO7zbpru8MnAU5m5r23Z48ApDbc7Km6OiAcj4rqIOG7YycyWiJgPHJGZT7ct/h+m\nZ79fXe33f4qIxcNOpmErgduncJ+vBG5v+3ua9jkwhdVyFi3PzLOBc4FngRuHnI9mxwcyc1m179cC\ndww7oaZExJXADHDlsHOZTR36PTX7vF3TxeMJ4MSIaG/nFFpHHxMtM7dW/9wLfJbWOfKpkJnbgT0R\ncXzb4kVMx37f1vb+C8CpEfGGIabUiIj4FHAxresAu6Zlnx/cb5iefX6wRotHZj4DrAMuB4iI9wJP\nZOamJtsdtog4OiLmtS16H7B+WPkMyS3AxwAi4h20Li7fN9SMGhYRc9r/5xkRK4AfZeZPhpjWwEXE\nKuAy4N2ZuaPto4ne5536PS37vJOoRgs010DEUuAG4I3A88AVmfn9Rhsdsuqc5620inPQGpGzMjMn\n6lcYQESsBt4DnEDr9NyOzFxa/Qd1M7AY2A18PDO/MbxMB6tTv4GzgW8ArwUSeAZYlZnfG1aegxYR\nC2idUXiMVp8D2JWZ75zkfd6t38D5tArkxO7zbhovHpKkyeMFc0lSMYuHJKmYxUOSVMziIUkqdsQg\nNxYRQWt43o7DxUqSRt6xwJPZYWTVQIsHrcKxdcDblCQNz0m05in7fwZdPKojjj8FjjroozuBCzus\n8nIfzRROl/MHK4pbuPrz8w4f1KbbHUF30xoI3snffOb5ojb4w2+WxfNAYTy0hq4PQq+eHzugNkZR\nt+/5pLPfk2cX8BfQ5UxS7eIREUtozc90HPAc8KHMfKhz9FEcWjzmdFi2f3mpo8vC5/5scQudMu3Z\nRJflc3p8xutK8zqmML60F9C6z2kQevW8n7zGRbfv+aSz39Om5IL5tcDqzDwd+Fuc6E+Splat4jGY\n53Kc3kd6429m2AkMzbT2fDq/5/Z7+tQ98hjAczmW1Q+dIEuGncDQTGvPp/N7br+nz6AvmFfu5MC1\njNOZ5n/BkjQ+HgYeqd7v7RlZt3i88lyOtqOPHs/luJBpvYgkSeNrGQd+7O8C7u8aWeu01bQ+l0OS\n1FnJaauPAjdUj2B8HriimZQkSaOudvHIzI3AuxrMRZI0JpwYUZJUrKHRVqdS/y7wfqYnOass/GfK\nW1iR84viF9yzvbiNq/6leJVCR/axzosDz+JQ0zqMVxonO3t+6pGHJKlY3TvMr4mIzRGxLyIKf/ZL\nkiZN3SOPW4BfArY0l4okaVzUuuaRmWvhlYc9SZKmnNc8JEnFGhptdXPbps8Bzm2mGUnSAK0D1lfv\n9/SMbKh4XE7xA5skSUN2Lgd+7O+kNcltZ562kiQVqztUd3VEPAEsANZExMZm05IkjbK6o60+2nQi\nkqTx4WkrSVKxhi6Yb6L+w6D6mdvq6bLwPz+tvIlPl4V/7vzyJj6Zf1kU//c/+pOyBr5SNj9Xy32F\n8S/00caWPtaRNLt29fzUIw9JUrG6F8znRsRtEfFwRKyPiDURMdN0cpKk0VRy5HFtZi7LzHOArwLX\nN5STJGnE1X2G+e7MvKtt0QPAwmZSkiSNun6veawEbh9kIpKk8VE82ioirgRmgI8MPh1J0jgoKh4R\n8SngYuD8zOwxjutOYE71/nRgWZ/pSZJmz0PAw9X7AU2MGBGrgMtoFY4dvaMvpP59HpKk0XBG9YLW\nfR5ru0bWKh4RsQD4O+Ax4N7qoVC7MvOdry5RSdI4qju31Ta8oVCSVLEgSJKKWTwkScUamhjxZOo/\nSbD3Ff3OCh9r+5XyFhacub0o/hPbytuINxROdPjcDYUtbCmMny2Lhp2ApMPa2fNTjzwkScVKhuqu\nAU4AEvgpsCozv9VUYpKk0VVy2uqSzHwBICIuBm4A3tpEUpKk0Vb7tNX+wlF5PfDjwacjSRoHpdOT\n3Aj8Kq2i08ez8yRJk6CoeGTm7wBExAeB2+h62urLwJHV+7dVL0nSaHuwesHA5rZql5k3RcTqiJif\nmR3GtL6f+kN1JUmj4ezqBa2hul/rGln3MbTzIuLEtr8vBrZ1LhySpElX98hjHnBLRBwF7KV1sfyi\nxrKSJI20uhMjPg78YsO5SJLGhHeYS5KKNTS31Q+Auc1sGmg97arAZfOLW4gLsig+Px3FbeSNZetc\nd9EHiuI/xyeK4gE2LH5H2QpbvlrcBqzrYx1Js2t3z0898pAkFSsuHhFxRUTsiwgvmEvSlCoqHhGx\nEPg94JvNpCNJGge1i0f13PLrgd8HXmosI0nSyCs58lgF/Gdmrm8qGUnSeKg12ioifg5YASxvNh1J\n0jioO1R3ObAQeLQ6ffVm4B8i4sTMvPbQ8LuBOdX7GWDJq89UktSwHwKPVe/39oyse4f5amD1/r8j\n4l7gM5nZZZD/+TR7n4ckafCWcODH/m7g210j+73Po+wOOknSROl3SvZfG3QikqTx4R3mkqRiFg9J\nUrGGJkYcNTvKV/lOWfijd5U3cdrasvjjL3q6KH7DNYWTHAJsebZwhR+XtyFp7HnkIUkqVvvIIyK2\nAC8Cu2iNtvrrzLylobwkSSOs5LTVPuDSzPxeU8lIksZDyWmrqF6SpClXes3j5oh4MCKui4jjGslI\nkjTySk5bLc/MrRExB/gr4EbgPZ1DndtKksbPgOe2AsjMrdU/90bEZ4FHukc7t5UkjZ8Bz20VEUdH\nxLy2Re8DfK6HJE2pukceJwC3RsRraF003wR8sLGsJEkjre6U7JuBcxvORZI0JrzDXJJUbErmtnq5\nfJX/va4ofOkP9xU3kTeV1e7fPOVrRfEbHp8pigf4+X9/7PBB7e44o7gN2NbHOpJGiUcekqRitYtH\nRLw2Ij4fERurGwVvajIxSdLoKjltdTWwLzOXAkTE8c2kJEkadbWKR0QcDXwYWLB/WWaWPVxCkjQx\n6p62mgG2A38cEd+OiPsiwueYS9KUqnva6ghgIbAhM/8oIt4GfD0i3pqZzxwa7txWkjR+Bj+31ePV\nlv4RIDO/GxGbgTOBew4Nd24rSRo/A57bKjOfpXU4cQFARCwGFgEPvYosJUljqmS01ceAL0bE1bSO\nQj6SmU81k5YkaZSVTMm+GfAiuSTJO8wlSeUsHpKkYg1NjHgEcGQzm35l+yUWlTdx0m8Vhf/2zJeK\nm/jnq369KP7Jq04sil/MlqJ4AN5bGH/HeeVtcH8f60iaXdHz07p3mM+nNdoqq0XHAIuB4zPzuVeT\nniRp/NR9GNR24Jz9f0fEJ4FftnBI0nTq95rH7wLXDzIRSdL4KC4eEfEu4PXAvw4+HUnSOOjnyOPD\nwE2ZWf7oPEnSRCgathQRxwCXAm/vHfl1DkyMeFr1kiSNto3VC2BPz8jSMa+XAd/NzI29w94NHFW4\naUnScC2tXgC7gAe6RpaetrqCvi+UP9rfamPuqTUbhp3CkKwZdgJDcpjfVRPLfk+bouKRmedlZp/P\nLrd4TBeLx3Sx39PG6UkkScUamp5kd4dle2mdQxuE0rR3ljex74Wi8JdfeLHzZl7a0/WznYe5IHWw\nF3mpKP6nhdtvNVLW7+5eArpta1Dfg1G0h8nuXzf2e/L07ldkZs+AEhGxANg6sA1KkobtpMzcdvDC\nQRePAN4C7BjYRiVJw3Is8GR2KBQDLR6SpOngBXNJUjGLhySpmMVDklTM4iFJKmbxkCQV+z9VoWpK\nVp7MAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3e19350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam search using time(ms): 404.276132584\n"
     ]
    }
   ],
   "source": [
    "inference('美国代购Vaseline凡士林深层滋润保湿修复护手霜护甲')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
